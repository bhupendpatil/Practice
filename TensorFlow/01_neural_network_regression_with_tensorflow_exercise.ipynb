{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaxAsUFqsPA"
      },
      "source": [
        "# **ðŸ›  01 Neural network regression with TensorFlow Exercises**\n",
        "[Source](https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises)\n",
        "\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "\n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibdLN72aRSD6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL51hb3NZLMR"
      },
      "source": [
        "## 1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nr84c7SFcsU"
      },
      "source": [
        "# Create dataset\n",
        "X = tf.range(-100,100,4)\n",
        "y = X + 10"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mJ7kIzj7RvHf",
        "outputId": "48e9532b-c150-42f3-86fe-01abbcca33fa"
      },
      "source": [
        "plt.scatter(X,y)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f0f7a472a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrSagkZbu1Z",
        "outputId": "65d53fc4-74ca-4017-b606-86f60de2d1ff"
      },
      "source": [
        "X,y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7C2pbyZ6Oo"
      },
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train = X[:40] \n",
        "X_test = X[40:] \n",
        "y_train = y[:40] \n",
        "y_test = y[40:]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmm78ICIR74F",
        "outputId": "766e10d1-2778-44a1-a50d-66d624b4ff7e"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_1.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 3s 9ms/step - loss: 35.4040 - mae: 35.4040\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.2785 - mae: 31.2785\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 27.5044 - mae: 27.5044\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.3802 - mae: 24.3802\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.0951 - mae: 22.0951\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.1109 - mae: 19.1109\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.2483 - mae: 17.2483\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6597 - mae: 15.6597\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.4223 - mae: 14.4223\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3527 - mae: 13.3527\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.3092 - mae: 12.3092\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.2891 - mae: 11.2891\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3441 - mae: 10.3441\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5942 - mae: 9.5942\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7595 - mae: 8.7595\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0242 - mae: 8.0242\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7121 - mae: 7.7121\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4682 - mae: 7.4682\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5419 - mae: 7.5419\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.7871 - mae: 7.7871\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5730 - mae: 7.5730\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4983 - mae: 7.4983\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8575 - mae: 7.8575\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9629 - mae: 7.9629\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5983 - mae: 7.5983\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6955 - mae: 7.6955\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.4287 - mae: 7.4287\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5633 - mae: 7.5633\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5406 - mae: 7.5406\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6757 - mae: 7.6757\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5985 - mae: 7.5985\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5266 - mae: 7.5266\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5310 - mae: 7.5310\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4781 - mae: 7.4781\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5740 - mae: 7.5740\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5818 - mae: 7.5818\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4732 - mae: 7.4732\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0885 - mae: 8.0885\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5031 - mae: 7.5031\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6693 - mae: 7.6693\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8779 - mae: 7.8779\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6900 - mae: 7.6900\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4488 - mae: 7.4488\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6352 - mae: 7.6352\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7237 - mae: 7.7237\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5711 - mae: 7.5711\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6887 - mae: 7.6887\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9564 - mae: 7.9564\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6881 - mae: 7.6881\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4656 - mae: 7.4656\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.4659 - mae: 7.4659\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.7672 - mae: 7.7672\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.7817 - mae: 7.7817\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6056 - mae: 7.6056\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4338 - mae: 7.4338\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5941 - mae: 7.5941\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.8224 - mae: 7.8224\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4502 - mae: 7.4502\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5045 - mae: 7.5045\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6902 - mae: 7.6902\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7729 - mae: 7.7729\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6792 - mae: 7.6792\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6778 - mae: 7.6778\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.5204 - mae: 7.5204\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5205 - mae: 7.5205\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6055 - mae: 7.6055\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6647 - mae: 7.6647\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4083 - mae: 7.4083\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.5393 - mae: 7.5393\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6690 - mae: 7.6690\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6172 - mae: 7.6172\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5069 - mae: 7.5069\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.4572 - mae: 7.4572\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5076 - mae: 7.5076\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5044 - mae: 7.5044\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3708 - mae: 7.3708\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8612 - mae: 7.8612\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.8388 - mae: 7.8388\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6186 - mae: 7.6186\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.7673 - mae: 7.7673\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6879 - mae: 7.6879\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 7.7141 - mae: 7.7141\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.7475 - mae: 7.7475\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6173 - mae: 7.6173\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6258 - mae: 7.6258\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5187 - mae: 7.5187\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.7281 - mae: 7.7281\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5778 - mae: 7.5778\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7908 - mae: 7.7908\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4257 - mae: 7.4257\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6705 - mae: 7.6705\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0292 - mae: 8.0292\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5379 - mae: 7.5379\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6017 - mae: 7.6017\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6669 - mae: 7.6669\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8249 - mae: 7.8249\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0588 - mae: 8.0588\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5921 - mae: 7.5921\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6860 - mae: 7.6860\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6649 - mae: 7.6649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0f79894750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY5Tspgefve",
        "outputId": "a3c5e5b7-f6fe-4a35-a2a6-c962cbfbaa51"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa0TpHTdy8H"
      },
      "source": [
        "## 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l8rGvb1ccMg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}