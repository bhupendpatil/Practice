{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaxAsUFqsPA"
      },
      "source": [
        "# **ðŸ›  01 Neural network regression with TensorFlow Exercises**\n",
        "[Source](https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises)\n",
        "\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "\n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibdLN72aRSD6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL51hb3NZLMR"
      },
      "source": [
        "## 1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nr84c7SFcsU"
      },
      "source": [
        "# Create dataset\n",
        "X = tf.range(-100,100,4)\n",
        "y = X + 10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mJ7kIzj7RvHf",
        "outputId": "6223154d-d52f-43e2-dd67-797ed78a53a8"
      },
      "source": [
        "plt.scatter(X,y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4ae3ab18d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVC0lEQVR4nO3df+xldX3n8edr8UeItQuWWToOTGdwgV1MswN8w5qgJgoWIa2Api5s4uJqOjUr2brdpR1k05htTFGWmjRtdIeUFDcquuWHpKWLIG672yzWGWc6DALLDIXI13EYdRGzEir43j++54t3xnvnO9/vPffXuc9HcnPP/Zx773nPuZf3nHndD+ekqpAkddM/mHQBkqTRsclLUofZ5CWpw2zyktRhNnlJ6rCXTbqAXieddFJt2rRp0mVI0kzZuXPnd6pqXb91U9XkN23axI4dOyZdhiTNlCRPDlpnXCNJHWaTl6QOs8lLUofZ5CWpw2zyktRhUzW7RpLmzZ27Frnhnkf51jPP8doTjueai87ksrM3tPb+NnlJmpA7dy1y7e0P8tyPXgRg8ZnnuPb2BwFaa/TGNZI0ITfc8+hLDX7Zcz96kRvuebS1bdjkJWlCvvXMc6saXwvjGkkag37Z+2tPOJ7FPg39tScc39p2PZKXpBFbzt4Xn3mO4ifZ+1v+yTqOf/lxhz33+JcfxzUXndnatlfV5JPcnOTpJHt7xl6T5N4kjzX3JzbjSfIHSfYl2ZPknNaqlqQZMih7/8ojh/i9d/4iG044ngAbTjie33vnL050ds2fAH8IfLpnbBvw5aq6Psm25vFvAxcDpze3fw58srmXpLlytOz9srM3tNrUj7SqI/mq+ivge0cMXwrc0izfAlzWM/7pWvIAcEKS9cMUK0nT7M5di5x//f1s3vbnnH/9/dy5axEYnLG3mb0P0kYmf3JVHWiWvw2c3CxvAL7Z87ynmrHDJNmaZEeSHYcOHWqhHEkav0G5+527FrnmojNHnr0P0uoPr1VVQK3yNduraqGqFtat63vOe0maekeb837Z2RtGnr0P0sYUyoNJ1lfVgSaOeboZXwRO7XneKc2YJHXOSnPeR529D9JGk78LuAq4vrn/Ys/41UluZekH1+/3xDqSNLMmNed9LVY7hfJzwP8GzkzyVJL3s9Tc35bkMeDC5jHA3cDjwD7gJuDftFa1JE3IJOe8r8WqjuSr6soBqy7o89wCPriWoiRpWq00532UZ5RcC09rIEmrMMk572thk5ekAWYpex/Ec9dIUh+zlr0PYpOXpD4meb6ZNhnXSFIfs5a9D2KTlzT3upC9D2JcI2mudSV7H8QmL2mudSV7H8S4RtJc60r2PohNXtLc6HL2PohxjaS50PXsfRCbvKS50PXsfRDjGklzoevZ+yA2eUmd0i93v+zsDZ3P3gcxrpHUGdN6ndVJsslL6oxpvc7qJA0d1yQ5E/h8z9BpwO8AJwC/Bhxqxj9cVXcPuz1JGmRar7M6SUMfyVfVo1W1paq2AOcCPwTuaFZ/YnmdDV7SqA3K17ueux9N2z+8XgDsr6onk7T81pL0E/1+YL3mojO59vYHD4ts5iF3P5q2M/krgM/1PL46yZ4kNyc5seVtSZpTg35gBeYydz+aLF1vu4U3Sl4BfAt4fVUdTHIy8B2ggN8F1lfV+/q8biuwFWDjxo3nPvnkk63UI6m7zr/+/r7TITeccDx/ve2tE6hospLsrKqFfuvaPJK/GPh6VR0EqKqDVfViVf0YuAk4r9+Lqmp7VS1U1cK6detaLEdSV630A6t+os1M/kp6opok66vqQPPwcmBvi9uSNCfm8aRibWrlSD7Jq4C3Abf3DH88yYNJ9gBvAf5dG9uSND/m9aRibWrlSL6q/h/wc0eMvaeN95Y0v1Y6qVi/0xfocJ67RtLUmteTirXJJi9pKpi9j4bnrpE0cWbvo2OTlzRx83pBj3EwrpE0cWbvo2OTlzRWZu/jZVwjaWzM3sfPJi9pbMzex8+4RtLYmL2Pn01eUuu8mPb0MK6R1Covpj1dbPKSWuXFtKeLcY2kVnkx7elik5e0Zs55n37GNZLWxDnvs8EmL2lNnPM+G4xrJK2Jc95nQ2tNPskTwA+AF4EXqmohyWuAzwObgCeAd1fV/21rm5LGw+x9drUd17ylqrZU1ULzeBvw5ao6Hfhy81jSDDF7n22jzuQvBW5plm8BLhvx9iS1zOx9trWZyRfwpSQF/Jeq2g6cXFUHmvXfBk4+8kVJtgJbATZu3NhiOZLaYPY+29ps8m+sqsUk/wi4N8kjvSurqpq/ADhifDuwHWBhYeGn1ksaH7P37mktrqmqxeb+aeAO4DzgYJL1AM39021tT1K7zN67qZUmn+RVSV69vAz8ErAXuAu4qnnaVcAX29iepPaZvXdTW3HNycAdSZbf87NV9d+TfA34QpL3A08C725pe5JaZvbeTa00+ap6HPhnfca/C1zQxjYktcfsfX54WgNpzpi9zxebvDRnzN7ni+eukeaM2ft8sclLHeV1VgXGNVIneZ1VLbPJSx3kdVa1zLhG6iCvs6plNnlpxjnnXUdjXCPNMOe8ayU2eWmGOeddKzGukWaYc961Epu8NCPM3rUWxjXSDDB711rZ5KUZYPautTKukWaA2bvWyiYvTRmzd7Vp6LgmyalJvpLkG0keSvIbzfhHkiwm2d3cLhm+XKnbzN7VtjYy+ReAf19VZwFvAD6Y5Kxm3Seqaktzu7uFbUmdZvautg0d11TVAeBAs/yDJA8DfvOkNTB7V9tanV2TZBNwNvDVZujqJHuS3JzkxAGv2ZpkR5Idhw4darMcaWrduWuR86+/n83b/pzzr7+fO3ctAoMzdrN3rVVrTT7JzwC3AR+qqmeBTwKvA7awdKR/Y7/XVdX2qlqoqoV169a1VY40tTzXu8aplSaf5OUsNfjPVNXtAFV1sKperKofAzcB57WxLWnWea53jdPQmXySAH8MPFxVv98zvr7J6wEuB/YOuy2pCzzXu8apjXny5wPvAR5MsrsZ+zBwZZItQAFPAL/ewrakmeKcd01aG7Nr/heQPqucMqm5tpy9L0czy9n7u87dwG07Fw+LbMzdNSqeu0YaEee8axp4WgNpRJzzrmlgk5daYPauaWVcIw3J881omtnkpSGZvWuaGddIQzJ71zSzyUurYPauWWNcIx0js3fNIpu8dIzM3jWLjGukY2T2rllkk5f6MHtXVxjXSEcwe1eX2OSlI5i9q0uMa6QjmL2rS2zymlv9cvfLzt5g9q5OMa7RXPI6q5oXI2/ySd6e5NEk+5JsG/X2pGPhdVY1L0Ya1yQ5Dvgj4G3AU8DXktxVVd8Y5XallXidVc2LUWfy5wH7qupxgCS3ApcCNnmNjXPeNc9GHddsAL7Z8/ipZuwlSbYm2ZFkx6FDh0ZcjuaNc9417yb+w2tVba+qhapaWLdu3aTLUcc4513zbtRxzSJwas/jU5oxaSyc8655N+om/zXg9CSbWWruVwD/csTb1Jwye5d+2kjjmqp6AbgauAd4GPhCVT00ym1qPpm9S/2NPJOvqrur6oyqel1VfXTU29N8MnuX+vO0BuoEs3epP5u8Zo7Zu3TsJj6FUloNs3dpdWzymilm79LqGNdoppi9S6tjk9fUMnuXhmdco6lk9i61wyavqWT2LrXDuEZTyexdaodNXhPldVal0TKu0cR4nVVp9GzymhivsyqNnnGNJsbrrEqjZ5PXWDjnXZoM4xqNnHPepcmxyWvknPMuTc5QcU2SG4BfAf4e2A/866p6Jskmlq4E9Wjz1Aeq6gPDbEuzyznv0uQMm8nfC1xbVS8k+RhwLfDbzbr9VbVlyPfXjDF7l6bLUHFNVX2puY4rwAPAKcOXpFll9i5NnzYz+fcBf9HzeHOSXUn+MsmbBr0oydYkO5LsOHToUIvlaNzM3qXps2Jck+Q+4Of7rLquqr7YPOc64AXgM826A8DGqvpuknOBO5O8vqqePfJNqmo7sB1gYWGh1vbH0DQwe5emz4pNvqouPNr6JO8Ffhm4oKqqec3zwPPN8s4k+4EzgB3DFqzpYPYuzYah4pokbwd+C3hHVf2wZ3xdkuOa5dOA04HHh9mWpofZuzQ7hs3k/xB4NXBvkt1JPtWMvxnYk2Q38KfAB6rqe0NuS1PC7F2aHUNNoayqfzxg/DbgtmHeW9PL7F2aHZ67Rkdl9i7NNk9roIHM3qXZZ5PXQGbv0uwzrtFAZu/S7LPJy+usSh1mXDPnvM6q1G02+TnndValbjOumXNeZ1XqNo/k59ygfN3cXeoGj+TnSL8fWK+56Eyuvf3BwyIbc3epOzySnxODfmAFzN2lDvNIfk4c7QfWv972Vpu61FEeyc+JlX5gldRNHsl3kCcVk7TMI/mO8aRiknrZ5DvGk4pJ6jVUXJPkI8CvAYeaoQ9X1d3NumuB9wMvAv+2qu4ZZls6Np5UTFKvNjL5T1TVf+4dSHIWcAXweuC1wH1JzqiqF/u9gdbG7F3SSkYV11wK3FpVz1fV3wH7gPNGtK25ZPYu6Vi00eSvTrInyc1JTmzGNgDf7HnOU82YWmL2LulYrBjXJLkP+Pk+q64DPgn8LlDN/Y3A+1ZTQJKtwFaAjRs3rualc83sXdKxWLHJV9WFx/JGSW4C/qx5uAic2rP6lGas3/tvB7YDLCws1LFsa554QQ9Jwxgqrkmyvufh5cDeZvku4Iokr0yyGTgd+JthtjWPvKCHpGENO7vm40m2sBTXPAH8OkBVPZTkC8A3gBeADzqzZvVWOt/M8nOOPMqXpGVDNfmqes9R1n0U+Ogw7z/vvKCHpGF57pop4Zx3SaPgaQ2mgHPeJY2KTX4KOOdd0qgY10wB57xLGhWb/JiZvUsaJ+OaMTJ7lzRuNvkxMnuXNG7GNWNk9i5p3GzyI2L2LmkaGNeMgNm7pGlhkx8Bs3dJ08K4ZgTM3iVNC5v8kMzeJU0z45ohmL1LmnY2+SGYvUuadsY1QzB7lzTtbPLHwOusSppVw17j9fNJdje3J5LsbsY3JXmuZ92n2il3/LzOqqRZNuzl//7F8nKSG4Hv96zeX1Vbhnn/aeB1ViXNslbimiQB3g28tY33myZeZ1XSLGsrk38TcLCqHusZ25xkF/As8B+r6n/2e2GSrcBWgI0bN7ZUzto4511S16yYySe5L8nePrdLe552JfC5nscHgI1VdTbwm8Bnk/xsv/evqu1VtVBVC+vWrRvmzzIU57xL6qIVj+Sr6sKjrU/yMuCdwLk9r3keeL5Z3plkP3AGsGOoakdopTnv5u6SZlEbcc2FwCNV9dTyQJJ1wPeq6sUkpwGnA4+3sK2Rcc67pC5qo8lfweFRDcCbgf+U5EfAj4EPVNX3WthWK8zeJc2LoZt8Vb23z9htwG3DvvcoLGfvy9HMcvb+rnM3cNvOxcMiG7N3SbNu7s5d4/lmJM2TuTutgdm7pHnS6SZv9i5p3nU2rnHeuyR1uMmbvUtSh+Mas3dJ6kiTN3uXpP5mPq4xe5ekwWa+yZu9S9JgMx/XmL1L0mAzfyQ/KGM3e5ekDjR5r7MqSYPNfFyzHMd4vndJ+mkz3+TB66xK0iAzH9dIkgazyUtSh9nkJanDbPKS1GE2eUnqsFTVpGt4SZJDwJNDvMVJwHdaKqdN01oXWNtaWdvqTWtdMPu1/UJVreu3Yqqa/LCS7KiqhUnXcaRprQusba2sbfWmtS7odm3GNZLUYTZ5SeqwrjX57ZMuYIBprQusba2sbfWmtS7ocG2dyuQlSYfr2pG8JKmHTV6SOmwmm3ySX03yUJIfJ1k4Yt21SfYleTTJRT3jb2/G9iXZNqY6P59kd3N7IsnuZnxTkud61n1qHPUcUdtHkiz21HBJz7q++3CMtd2Q5JEke5LckeSEZnwa9tvYv0dHqeXUJF9J8o3mv4ffaMYHfrZjru+JJA82Nexoxl6T5N4kjzX3J06grjN79s3uJM8m+dCk9luSm5M8nWRvz1jf/ZQlf9B8//YkOWfFDVTVzN2AfwqcCfwPYKFn/Czgb4FXApuB/cBxzW0/cBrwiuY5Z4255huB32mWNwF7J7wPPwL8hz7jfffhmGv7JeBlzfLHgI9Nw36bhu/REfWsB85pll8N/J/m8+v72U6gvieAk44Y+ziwrVnetvzZTvgz/TbwC5Pab8CbgXN6v9uD9hNwCfAXQIA3AF9d6f1n8ki+qh6uqkf7rLoUuLWqnq+qvwP2Aec1t31V9XhV/T1wa/PcsUgS4N3A58a1zSEM2odjU1VfqqoXmocPAKeMc/tHMdHv0ZGq6kBVfb1Z/gHwMDDtF1a4FLilWb4FuGyCtQBcAOyvqmH+T/uhVNVfAd87YnjQfroU+HQteQA4Icn6o73/TDb5o9gAfLPn8VPN2KDxcXkTcLCqHusZ25xkV5K/TPKmMdbS6+rmn3w39/yzedL76kjvY+nIZdkk99u07ZuXJNkEnA18tRnq99mOWwFfSrIzydZm7OSqOtAsfxs4eTKlveQKDj/4mob9BoP306q/g1Pb5JPcl2Rvn9vEjpz6OcY6r+TwL9IBYGNVnQ38JvDZJD875to+CbwO2NLUc2Pb2x+ituXnXAe8AHymGRrLfps1SX4GuA34UFU9y4Q/2x5vrKpzgIuBDyZ5c+/KWsofJjaHO8krgHcA/60Zmpb9dphh99PUXv6vqi5cw8sWgVN7Hp/SjHGU8aGsVGeSlwHvBM7tec3zwPPN8s4k+4EzgB1t1HSstfXUeBPwZ83Do+3D1hzDfnsv8MvABc2XfGz77SjGsm9WI8nLWWrwn6mq2wGq6mDP+t7PdqyqarG5fzrJHSzFXQeTrK+qA03M8PQkamtcDHx9eX9Ny35rDNpPq/4OTu2R/BrdBVyR5JVJNgOnA38DfA04Pcnm5m/vK5rnjsOFwCNV9dTyQJJ1SY5rlk9r6nx8TPUs19Cb410OLP+yP2gfjrO2twO/Bbyjqn7YMz7p/TbJ79FPaX7r+WPg4ar6/Z7xQZ/tOGt7VZJXLy+z9GP6Xpb211XN064Cvjju2noc9i/sadhvPQbtp7uAf9XMsnkD8P2eWKe/Sf6yPcSv0ZezlEU9DxwE7ulZdx1LMyAeBS7uGb+EpdkH+4HrxljrnwAfOGLsXcBDwG7g68CvTGAf/lfgQWBP88VZv9I+HGNt+1jKHXc3t09N0X6byPdoQC1vZOmf8Xt69tUlR/tsx1jbaSzNPvrb5jO7rhn/OeDLwGPAfcBrJrTvXgV8F/iHPWMT2W8s/UVzAPhR09feP2g/sTSr5o+a79+D9MwuHHTztAaS1GFdi2skST1s8pLUYTZ5Seowm7wkdZhNXpI6zCYvSR1mk5ekDvv/Gg0+q3BJ5t4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrSagkZbu1Z",
        "outputId": "a92d7f6f-91a0-42a4-c30f-e78820dd495d"
      },
      "source": [
        "X,y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7C2pbyZ6Oo"
      },
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train = X[:40] \n",
        "X_test = X[40:] \n",
        "y_train = y[:40] \n",
        "y_test = y[40:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmm78ICIR74F",
        "outputId": "75f3798c-b464-4471-9090-3b8e7476f5aa"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_1.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 38.5706 - mae: 38.5706\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 35.7745 - mae: 35.7745\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 33.0355 - mae: 33.0355\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.4108 - mae: 29.4108\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.0104 - mae: 26.0104\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.9343 - mae: 23.9343\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.0963 - mae: 22.0963\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.9661 - mae: 19.9661\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9770 - mae: 17.9770\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3034 - mae: 16.3034\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.8174 - mae: 14.8174\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.9614 - mae: 12.9614\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6739 - mae: 11.6739\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0359 - mae: 10.0359\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4028 - mae: 9.4028\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0788 - mae: 9.0788\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.2832 - mae: 8.2832\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0750 - mae: 8.0750\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7782 - mae: 7.7782\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.4792 - mae: 7.4792\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.5015 - mae: 7.5015\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.7733 - mae: 7.7733\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6228 - mae: 7.6228\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6427 - mae: 7.6427\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7336 - mae: 7.7336\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9244 - mae: 7.9244\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9835 - mae: 7.9835\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4915 - mae: 7.4915\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6477 - mae: 7.6477\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6943 - mae: 7.6943\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7416 - mae: 7.7416\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5174 - mae: 7.5174\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8084 - mae: 7.8084\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7519 - mae: 7.7519\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2474 - mae: 7.2474\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9898 - mae: 7.9898\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0849 - mae: 8.0849\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6993 - mae: 7.6993\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7894 - mae: 7.7894\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6296 - mae: 7.6296\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8347 - mae: 7.8347\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5715 - mae: 7.5715\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3796 - mae: 7.3796\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5348 - mae: 7.5348\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6536 - mae: 7.6536\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6126 - mae: 7.6126\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5407 - mae: 7.5407\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6698 - mae: 7.6698\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0207 - mae: 8.0207\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7310 - mae: 7.7310\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5135 - mae: 7.5135\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3192 - mae: 7.3192\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7657 - mae: 7.7657\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5927 - mae: 7.5927\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6693 - mae: 7.6693\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6302 - mae: 7.6302\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5011 - mae: 7.5011\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5613 - mae: 7.5613\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3390 - mae: 7.3390\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5980 - mae: 7.5980\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8723 - mae: 7.8723\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6968 - mae: 7.6968\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2091 - mae: 7.2091\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6940 - mae: 7.6940\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6769 - mae: 7.6769\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7671 - mae: 7.7671\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5633 - mae: 7.5633\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4946 - mae: 7.4946\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6247 - mae: 7.6247\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5679 - mae: 7.5679\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5265 - mae: 7.5265\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8299 - mae: 7.8299\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7647 - mae: 7.7647\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4800 - mae: 7.4800\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6929 - mae: 7.6929\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8004 - mae: 7.8004\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5540 - mae: 7.5540\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4819 - mae: 7.4819\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3297 - mae: 7.3297\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3902 - mae: 7.3902\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4473 - mae: 7.4473\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3422 - mae: 7.3422\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7362 - mae: 7.7362\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6385 - mae: 7.6385\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5556 - mae: 7.5556\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6696 - mae: 7.6696\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5556 - mae: 7.5556\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6464 - mae: 7.6464\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7077 - mae: 7.7077\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6214 - mae: 7.6214\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4594 - mae: 7.4594\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4779 - mae: 7.4779\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9425 - mae: 7.9425\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4402 - mae: 7.4402\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6856 - mae: 7.6856\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4339 - mae: 7.4339\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3860 - mae: 7.3860\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7632 - mae: 7.7632\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6548 - mae: 7.6548\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6522 - mae: 7.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4aa8638550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY5Tspgefve",
        "outputId": "5515e5b3-7581-45eb-a731-bd73df4aeb18"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa0TpHTdy8H"
      },
      "source": [
        "## 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l8rGvb1ccMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4738ad6-601b-4f44-fba6-6f6010602f1d"
      },
      "source": [
        "# model_2\n",
        "\n",
        "# Create a model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_2.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_2.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.9381 - mae: 13.9381\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3407 - mae: 12.3407\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9290 - mae: 10.9290\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4124 - mae: 9.4124\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9390 - mae: 7.9390\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9842 - mae: 7.9842\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3718 - mae: 8.3718\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4744 - mae: 8.4744\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4161 - mae: 8.4161\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0572 - mae: 8.0572\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5945 - mae: 7.5945\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5526 - mae: 7.5526\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5929 - mae: 7.5929\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7472 - mae: 7.7472\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3057 - mae: 7.3057\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4502 - mae: 7.4502\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4227 - mae: 7.4227\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1525 - mae: 7.1525\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4098 - mae: 7.4098\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4499 - mae: 7.4499\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.2986 - mae: 7.2986\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.3151 - mae: 7.3151\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.1759 - mae: 7.1759\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.9550 - mae: 6.9550\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3198 - mae: 7.3198\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0062 - mae: 7.0062\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.0085 - mae: 7.0085\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0624 - mae: 7.0624\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9782 - mae: 6.9782\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0098 - mae: 7.0098\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0974 - mae: 7.0974\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.2543 - mae: 7.2543\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8579 - mae: 6.8579\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3221 - mae: 7.3221\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9377 - mae: 6.9377\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9303 - mae: 6.9303\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9781 - mae: 6.9781\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0037 - mae: 7.0037\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0535 - mae: 7.0535\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0372 - mae: 7.0372\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7938 - mae: 6.7938\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8316 - mae: 6.8316\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7260 - mae: 6.7260\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7922 - mae: 6.7922\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8457 - mae: 6.8457\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7240 - mae: 6.7240\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.7970 - mae: 6.7970\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7170 - mae: 6.7170\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.7276 - mae: 6.7276\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7506 - mae: 6.7506\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6137 - mae: 6.6137\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6971 - mae: 6.6971\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.4684 - mae: 6.4684\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5665 - mae: 6.5665\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6371 - mae: 6.6371\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6364 - mae: 6.6364\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5880 - mae: 6.5880\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.5396 - mae: 6.5396\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5398 - mae: 6.5398\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.6445 - mae: 6.6445\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.5133 - mae: 6.5133\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2654 - mae: 6.2654\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3032 - mae: 6.3032\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1244 - mae: 6.1244\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4219 - mae: 6.4219\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3881 - mae: 6.3881\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2287 - mae: 6.2287\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2265 - mae: 6.2265\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2648 - mae: 6.2648\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0494 - mae: 6.0494\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3760 - mae: 6.3760\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.0562 - mae: 6.0562\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0615 - mae: 6.0615\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2053 - mae: 6.2053\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1395 - mae: 6.1395\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0722 - mae: 6.0722\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9823 - mae: 5.9823\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.1645 - mae: 6.1645\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1221 - mae: 6.1221\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9149 - mae: 5.9149\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9217 - mae: 5.9217\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.9817 - mae: 5.9817\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9542 - mae: 5.9542\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0033 - mae: 6.0033\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0121 - mae: 6.0121\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9314 - mae: 5.9314\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8635 - mae: 5.8635\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8267 - mae: 5.8267\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7372 - mae: 5.7372\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6851 - mae: 5.6851\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9046 - mae: 5.9046\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7347 - mae: 5.7347\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5362 - mae: 5.5362\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5834 - mae: 5.5834\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5799 - mae: 5.5799\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7434 - mae: 5.7434\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7441 - mae: 5.7441\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7373 - mae: 5.7373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a5d869e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrA8P9PXRizl",
        "outputId": "dc654fb6-10a7-4a5e-dc79-614c4dc5733b"
      },
      "source": [
        "model_1.evaluate(X_test,y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 150ms/step - loss: 19.4814 - mae: 19.4814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.48141098022461, 19.48141098022461]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZqh8x-SAF3",
        "outputId": "4305d2d5-2ac0-432a-a88f-2492d5ce3bc5"
      },
      "source": [
        "model_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 140ms/step - loss: 15.7954 - mae: 15.7954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.795373916625977, 15.795373916625977]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INiX8XI2ZKNd"
      },
      "source": [
        "model_1 loss is 18.4417 and model_2 loss is 17.8406, model_2 performs bit well than model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz2YvwscZuUP"
      },
      "source": [
        "## 3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8az4YJexKD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heTTDjEJeHTK"
      },
      "source": [
        "## Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDzJvi8yc8yk"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}