{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaxAsUFqsPA"
      },
      "source": [
        "# **ðŸ›  01 Neural network regression with TensorFlow Exercises**\n",
        "[Source](https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises)\n",
        "\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "\n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibdLN72aRSD6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL51hb3NZLMR"
      },
      "source": [
        "## 1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nr84c7SFcsU"
      },
      "source": [
        "# Create dataset\n",
        "X = tf.range(-100,100,4)\n",
        "y = X + 10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mJ7kIzj7RvHf",
        "outputId": "6223154d-d52f-43e2-dd67-797ed78a53a8"
      },
      "source": [
        "plt.scatter(X,y)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f4ae3ab18d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrSagkZbu1Z",
        "outputId": "a92d7f6f-91a0-42a4-c30f-e78820dd495d"
      },
      "source": [
        "X,y"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7C2pbyZ6Oo"
      },
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train = X[:40] \n",
        "X_test = X[40:] \n",
        "y_train = y[:40] \n",
        "y_test = y[40:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmm78ICIR74F",
        "outputId": "75f3798c-b464-4471-9090-3b8e7476f5aa"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_1.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 38.5706 - mae: 38.5706\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 35.7745 - mae: 35.7745\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 33.0355 - mae: 33.0355\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.4108 - mae: 29.4108\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.0104 - mae: 26.0104\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.9343 - mae: 23.9343\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.0963 - mae: 22.0963\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.9661 - mae: 19.9661\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.9770 - mae: 17.9770\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3034 - mae: 16.3034\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.8174 - mae: 14.8174\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.9614 - mae: 12.9614\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6739 - mae: 11.6739\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0359 - mae: 10.0359\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4028 - mae: 9.4028\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.0788 - mae: 9.0788\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.2832 - mae: 8.2832\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0750 - mae: 8.0750\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7782 - mae: 7.7782\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.4792 - mae: 7.4792\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 7.5015 - mae: 7.5015\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.7733 - mae: 7.7733\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6228 - mae: 7.6228\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6427 - mae: 7.6427\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7336 - mae: 7.7336\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9244 - mae: 7.9244\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9835 - mae: 7.9835\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4915 - mae: 7.4915\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6477 - mae: 7.6477\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6943 - mae: 7.6943\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7416 - mae: 7.7416\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5174 - mae: 7.5174\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8084 - mae: 7.8084\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7519 - mae: 7.7519\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2474 - mae: 7.2474\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9898 - mae: 7.9898\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0849 - mae: 8.0849\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6993 - mae: 7.6993\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7894 - mae: 7.7894\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6296 - mae: 7.6296\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8347 - mae: 7.8347\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5715 - mae: 7.5715\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3796 - mae: 7.3796\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5348 - mae: 7.5348\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6536 - mae: 7.6536\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6126 - mae: 7.6126\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5407 - mae: 7.5407\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6698 - mae: 7.6698\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0207 - mae: 8.0207\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.7310 - mae: 7.7310\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5135 - mae: 7.5135\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3192 - mae: 7.3192\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7657 - mae: 7.7657\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5927 - mae: 7.5927\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6693 - mae: 7.6693\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6302 - mae: 7.6302\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5011 - mae: 7.5011\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5613 - mae: 7.5613\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3390 - mae: 7.3390\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5980 - mae: 7.5980\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8723 - mae: 7.8723\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6968 - mae: 7.6968\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2091 - mae: 7.2091\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6940 - mae: 7.6940\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6769 - mae: 7.6769\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7671 - mae: 7.7671\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5633 - mae: 7.5633\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4946 - mae: 7.4946\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6247 - mae: 7.6247\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5679 - mae: 7.5679\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5265 - mae: 7.5265\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8299 - mae: 7.8299\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7647 - mae: 7.7647\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4800 - mae: 7.4800\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6929 - mae: 7.6929\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8004 - mae: 7.8004\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5540 - mae: 7.5540\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4819 - mae: 7.4819\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3297 - mae: 7.3297\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3902 - mae: 7.3902\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4473 - mae: 7.4473\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3422 - mae: 7.3422\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7362 - mae: 7.7362\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6385 - mae: 7.6385\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5556 - mae: 7.5556\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6696 - mae: 7.6696\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5556 - mae: 7.5556\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.6464 - mae: 7.6464\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7077 - mae: 7.7077\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6214 - mae: 7.6214\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4594 - mae: 7.4594\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4779 - mae: 7.4779\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9425 - mae: 7.9425\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4402 - mae: 7.4402\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6856 - mae: 7.6856\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4339 - mae: 7.4339\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3860 - mae: 7.3860\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7632 - mae: 7.7632\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6548 - mae: 7.6548\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6522 - mae: 7.6522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4aa8638550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY5Tspgefve",
        "outputId": "5515e5b3-7581-45eb-a731-bd73df4aeb18"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa0TpHTdy8H"
      },
      "source": [
        "## 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l8rGvb1ccMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4738ad6-601b-4f44-fba6-6f6010602f1d"
      },
      "source": [
        "# model_2\n",
        "\n",
        "# Create a model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_2.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_2.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.9381 - mae: 13.9381\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3407 - mae: 12.3407\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9290 - mae: 10.9290\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4124 - mae: 9.4124\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9390 - mae: 7.9390\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9842 - mae: 7.9842\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3718 - mae: 8.3718\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4744 - mae: 8.4744\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.4161 - mae: 8.4161\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0572 - mae: 8.0572\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5945 - mae: 7.5945\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5526 - mae: 7.5526\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5929 - mae: 7.5929\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7472 - mae: 7.7472\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3057 - mae: 7.3057\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4502 - mae: 7.4502\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4227 - mae: 7.4227\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1525 - mae: 7.1525\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4098 - mae: 7.4098\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.4499 - mae: 7.4499\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.2986 - mae: 7.2986\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.3151 - mae: 7.3151\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.1759 - mae: 7.1759\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.9550 - mae: 6.9550\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3198 - mae: 7.3198\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0062 - mae: 7.0062\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.0085 - mae: 7.0085\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0624 - mae: 7.0624\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9782 - mae: 6.9782\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0098 - mae: 7.0098\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0974 - mae: 7.0974\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 7.2543 - mae: 7.2543\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8579 - mae: 6.8579\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3221 - mae: 7.3221\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.9377 - mae: 6.9377\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9303 - mae: 6.9303\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9781 - mae: 6.9781\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0037 - mae: 7.0037\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0535 - mae: 7.0535\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0372 - mae: 7.0372\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7938 - mae: 6.7938\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8316 - mae: 6.8316\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7260 - mae: 6.7260\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.7922 - mae: 6.7922\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8457 - mae: 6.8457\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7240 - mae: 6.7240\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.7970 - mae: 6.7970\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7170 - mae: 6.7170\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 6.7276 - mae: 6.7276\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7506 - mae: 6.7506\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6137 - mae: 6.6137\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6971 - mae: 6.6971\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.4684 - mae: 6.4684\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5665 - mae: 6.5665\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6371 - mae: 6.6371\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6364 - mae: 6.6364\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5880 - mae: 6.5880\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.5396 - mae: 6.5396\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5398 - mae: 6.5398\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.6445 - mae: 6.6445\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.5133 - mae: 6.5133\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2654 - mae: 6.2654\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3032 - mae: 6.3032\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1244 - mae: 6.1244\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4219 - mae: 6.4219\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3881 - mae: 6.3881\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2287 - mae: 6.2287\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2265 - mae: 6.2265\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2648 - mae: 6.2648\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.0494 - mae: 6.0494\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3760 - mae: 6.3760\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.0562 - mae: 6.0562\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0615 - mae: 6.0615\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.2053 - mae: 6.2053\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1395 - mae: 6.1395\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0722 - mae: 6.0722\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9823 - mae: 5.9823\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.1645 - mae: 6.1645\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1221 - mae: 6.1221\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9149 - mae: 5.9149\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9217 - mae: 5.9217\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.9817 - mae: 5.9817\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9542 - mae: 5.9542\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0033 - mae: 6.0033\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0121 - mae: 6.0121\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9314 - mae: 5.9314\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8635 - mae: 5.8635\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.8267 - mae: 5.8267\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7372 - mae: 5.7372\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6851 - mae: 5.6851\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9046 - mae: 5.9046\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7347 - mae: 5.7347\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5362 - mae: 5.5362\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5834 - mae: 5.5834\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5799 - mae: 5.5799\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7434 - mae: 5.7434\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7441 - mae: 5.7441\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7373 - mae: 5.7373\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a5d869e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrA8P9PXRizl",
        "outputId": "dc654fb6-10a7-4a5e-dc79-614c4dc5733b"
      },
      "source": [
        "model_1.evaluate(X_test,y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 150ms/step - loss: 19.4814 - mae: 19.4814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[19.48141098022461, 19.48141098022461]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZqh8x-SAF3",
        "outputId": "4305d2d5-2ac0-432a-a88f-2492d5ce3bc5"
      },
      "source": [
        "model_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 140ms/step - loss: 15.7954 - mae: 15.7954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15.795373916625977, 15.795373916625977]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INiX8XI2ZKNd"
      },
      "source": [
        "model_1 loss is 18.4417 and model_2 loss is 17.8406, model_2 performs bit well than model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz2YvwscZuUP"
      },
      "source": [
        "## 3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4iv48GIYcJ6",
        "outputId": "59943df3-c445-4072-bcd7-c40f7e265d62"
      },
      "source": [
        "# Building a larger model (how does one with 4 dense layers go?).\n",
        "# model_3\n",
        "\n",
        "# Create a model\n",
        "model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_3.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_3.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.2879 - mae: 43.2879\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 45.6031 - mae: 45.6031\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 44.5884 - mae: 44.5884\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.1301 - mae: 43.1301\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 44.4516 - mae: 44.4516\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 44.2171 - mae: 44.2171\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 44.1188 - mae: 44.1188\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.1926 - mae: 43.1926\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.5322 - mae: 43.5322\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 43.7505 - mae: 43.7505\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.7365 - mae: 43.7365\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 43.4515 - mae: 43.4515\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.9489 - mae: 42.9489\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 42.5678 - mae: 42.5678\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 42.6996 - mae: 42.6996\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.7091 - mae: 42.7091\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 43.4778 - mae: 43.4778\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.0274 - mae: 41.0274\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 42.5902 - mae: 42.5902\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.9719 - mae: 40.9719\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.2943 - mae: 41.2943\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 41.6415 - mae: 41.6415\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 42.0401 - mae: 42.0401\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.8437 - mae: 41.8437\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 42.9665 - mae: 42.9665\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 41.5448 - mae: 41.5448\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.0227 - mae: 41.0227\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 42.3114 - mae: 42.3114\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 41.2017 - mae: 41.2017\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 40.1836 - mae: 40.1836\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.7958 - mae: 39.7958\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.8663 - mae: 39.8663\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.7275 - mae: 40.7275\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 40.9590 - mae: 40.9590\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 40.7678 - mae: 40.7678\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 40.9636 - mae: 40.9636\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.7755 - mae: 40.7755\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.2815 - mae: 39.2815\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.2773 - mae: 40.2773\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.8850 - mae: 39.8850\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.5410 - mae: 39.5410\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.0517 - mae: 40.0517\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 38.8679 - mae: 38.8679\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 39.8882 - mae: 39.8882\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 39.8589 - mae: 39.8589\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 39.2737 - mae: 39.2737\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 38.9991 - mae: 38.9991\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.2431 - mae: 39.2431\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 38.4840 - mae: 38.4840\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 37.9101 - mae: 37.9101\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 38.5178 - mae: 38.5178\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 39.0350 - mae: 39.0350\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 37.6388 - mae: 37.6388\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 37.8380 - mae: 37.8380\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 38.2286 - mae: 38.2286\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 38.4756 - mae: 38.4756\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 38.3599 - mae: 38.3599\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 37.6827 - mae: 37.6827\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 36.9683 - mae: 36.9683\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 38.2241 - mae: 38.2241\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 37.4584 - mae: 37.4584\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 36.6743 - mae: 36.6743\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 35.7284 - mae: 35.7284\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 36.5458 - mae: 36.5458\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 36.3160 - mae: 36.3160\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 34.7799 - mae: 34.7799\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 35.6704 - mae: 35.6704\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 35.9519 - mae: 35.9519\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 34.7743 - mae: 34.7743\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 35.3867 - mae: 35.3867\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 33.3668 - mae: 33.3668\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 33.6282 - mae: 33.6282\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 33.2032 - mae: 33.2032\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.9571 - mae: 31.9571\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.9492 - mae: 32.9492\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 33.2251 - mae: 33.2251\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.2561 - mae: 31.2561\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.7668 - mae: 31.7668\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 31.5383 - mae: 31.5383\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 30.2865 - mae: 30.2865\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.4163 - mae: 30.4163\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.2202 - mae: 30.2202\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.9488 - mae: 28.9488\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 28.3820 - mae: 28.3820\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.9514 - mae: 28.9514\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.6574 - mae: 27.6574\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.4464 - mae: 26.4464\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.7355 - mae: 25.7355\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.6466 - mae: 24.6466\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.3293 - mae: 25.3293\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.4049 - mae: 24.4049\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.2125 - mae: 23.2125\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.7629 - mae: 22.7629\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 22.2932 - mae: 22.2932\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.6591 - mae: 20.6591\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.9080 - mae: 20.9080\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 19.8574 - mae: 19.8574\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.7256 - mae: 18.7256\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.2491 - mae: 18.2491\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1887 - mae: 17.1887\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a5c675410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXHItzqaaqi1",
        "outputId": "21308000-51e5-4761-b101-2b968d430ece"
      },
      "source": [
        "model_3.evaluate(X_test,y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 119ms/step - loss: 43.0773 - mae: 43.0773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[43.077301025390625, 43.077301025390625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsAZavwSaLrJ",
        "outputId": "5e2dbe7d-27b6-4488-95e6-3c6055822f34"
      },
      "source": [
        "# Increasing the number of units in each layer.\n",
        "# model_4\n",
        "\n",
        "# Create a model\n",
        "model_4 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_4.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_4.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.6042 - mae: 40.6042\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 38.1729 - mae: 38.1729\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.8819 - mae: 34.8819\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 33.8587 - mae: 33.8587\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.7151 - mae: 29.7151\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 27.9882 - mae: 27.9882\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.3844 - mae: 25.3844\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 22.0660 - mae: 22.0660\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.1896 - mae: 20.1896\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.3422 - mae: 17.3422\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.3318 - mae: 15.3318\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.5985 - mae: 12.5985\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2341 - mae: 9.2341\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.6462 - mae: 7.6462\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9537 - mae: 7.9537\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9225 - mae: 8.9225\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3296 - mae: 9.3296\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.5926 - mae: 9.5926\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5230 - mae: 9.5230\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3146 - mae: 9.3146\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.8776 - mae: 8.8776\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3868 - mae: 8.3868\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7535 - mae: 7.7535\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3995 - mae: 7.3995\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7210 - mae: 7.7210\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9800 - mae: 7.9800\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0493 - mae: 8.0493\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9438 - mae: 7.9438\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1370 - mae: 8.1370\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5812 - mae: 7.5812\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0545 - mae: 7.0545\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3296 - mae: 7.3296\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.7709 - mae: 7.7709\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5708 - mae: 7.5708\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3904 - mae: 7.3904\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3399 - mae: 7.3399\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1476 - mae: 7.1476\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3749 - mae: 7.3749\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2340 - mae: 7.2340\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2524 - mae: 7.2524\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2621 - mae: 7.2621\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1872 - mae: 7.1872\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0484 - mae: 7.0484\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1528 - mae: 7.1528\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0464 - mae: 7.0464\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8299 - mae: 6.8299\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9760 - mae: 6.9760\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0291 - mae: 7.0291\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0206 - mae: 7.0206\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9298 - mae: 6.9298\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.8146 - mae: 6.8146\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9658 - mae: 6.9658\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8637 - mae: 6.8637\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8257 - mae: 6.8257\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8597 - mae: 6.8597\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6784 - mae: 6.6784\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8064 - mae: 6.8064\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5536 - mae: 6.5536\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7286 - mae: 6.7286\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.6337 - mae: 6.6337\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6629 - mae: 6.6629\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.4460 - mae: 6.4460\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.4906 - mae: 6.4906\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7104 - mae: 6.7104\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6032 - mae: 6.6032\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3279 - mae: 6.3279\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4586 - mae: 6.4586\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 6.5999 - mae: 6.5999\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5771 - mae: 6.5771\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6748 - mae: 6.6748\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6568 - mae: 6.6568\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5304 - mae: 6.5304\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7067 - mae: 6.7067\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4066 - mae: 6.4066\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.4332 - mae: 6.4332\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4053 - mae: 6.4053\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.5109 - mae: 6.5109\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3075 - mae: 6.3075\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3405 - mae: 6.3405\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4406 - mae: 6.4406\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1899 - mae: 6.1899\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2198 - mae: 6.2198\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.1198 - mae: 6.1198\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3093 - mae: 6.3093\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1577 - mae: 6.1577\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0768 - mae: 6.0768\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3889 - mae: 6.3889\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1139 - mae: 6.1139\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0009 - mae: 6.0009\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8378 - mae: 5.8378\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1226 - mae: 6.1226\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9684 - mae: 5.9684\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9240 - mae: 5.9240\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1286 - mae: 6.1286\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9157 - mae: 5.9157\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7435 - mae: 5.7435\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8356 - mae: 5.8356\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0799 - mae: 6.0799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a5b4e5290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz1QrVdwaayP",
        "outputId": "0d5079b1-907a-4555-f975-cd7f3d6f0d9a"
      },
      "source": [
        "model_4.evaluate(X_test,y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 125ms/step - loss: 14.5181 - mae: 14.5181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[14.51806640625, 14.51806640625]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJtGcIF9a34y",
        "outputId": "ac9dd0cc-9cf2-4c04-84ec-5f30b1a11169"
      },
      "source": [
        "# Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "#model_5\n",
        "\n",
        "# Create a model\n",
        "model_5 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_5.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_5.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 34.2421 - mae: 34.2421\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.9277 - mae: 29.9277\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.7389 - mae: 27.7389\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.0308 - mae: 25.0308\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.7683 - mae: 20.7683\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.3568 - mae: 17.3568\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.6245 - mae: 13.6245\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0993 - mae: 10.0993\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6613 - mae: 7.6613\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9648 - mae: 8.9648\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.4590 - mae: 10.4590\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1843 - mae: 11.1843\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4104 - mae: 11.4104\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.9575 - mae: 10.9575\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.3889 - mae: 10.3889\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.3905 - mae: 9.3905\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3863 - mae: 8.3863\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4126 - mae: 7.4126\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.9888 - mae: 7.9888\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.3278 - mae: 8.3278\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3500 - mae: 8.3500\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1175 - mae: 8.1175\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7297 - mae: 7.7297\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3540 - mae: 7.3540\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4957 - mae: 7.4957\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5252 - mae: 7.5252\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2819 - mae: 7.2819\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1166 - mae: 7.1166\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1688 - mae: 7.1688\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4232 - mae: 7.4232\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3250 - mae: 7.3250\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0917 - mae: 7.0917\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.1693 - mae: 7.1693\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1973 - mae: 7.1973\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0304 - mae: 7.0304\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8960 - mae: 6.8960\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1606 - mae: 7.1606\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0775 - mae: 7.0775\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.1536 - mae: 7.1536\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 6.8220 - mae: 6.8220\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0255 - mae: 7.0255\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9524 - mae: 6.9524\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0530 - mae: 7.0530\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0599 - mae: 7.0599\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1199 - mae: 7.1199\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 6.9425 - mae: 6.9425\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8755 - mae: 6.8755\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.8405 - mae: 6.8405\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5363 - mae: 6.5363\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6963 - mae: 6.6963\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7998 - mae: 6.7998\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5535 - mae: 6.5535\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7809 - mae: 6.7809\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.4228 - mae: 6.4228\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4544 - mae: 6.4544\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6339 - mae: 6.6339\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3707 - mae: 6.3707\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4149 - mae: 6.4149\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.3764 - mae: 6.3764\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5130 - mae: 6.5130\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3152 - mae: 6.3152\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6852 - mae: 6.6852\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4001 - mae: 6.4001\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3906 - mae: 6.3906\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3584 - mae: 6.3584\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0081 - mae: 6.0081\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9847 - mae: 5.9847\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2032 - mae: 6.2032\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2601 - mae: 6.2601\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1602 - mae: 6.1602\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.0524 - mae: 6.0524\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0556 - mae: 6.0556\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8838 - mae: 5.8838\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9495 - mae: 5.9495\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0845 - mae: 6.0845\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.1104 - mae: 6.1104\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8225 - mae: 5.8225\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9571 - mae: 5.9571\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9563 - mae: 5.9563\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8553 - mae: 5.8553\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7089 - mae: 5.7089\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8912 - mae: 5.8912\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5315 - mae: 5.5315\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6979 - mae: 5.6979\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7851 - mae: 5.7851\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6981 - mae: 5.6981\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5819 - mae: 5.5819\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.4503 - mae: 5.4503\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4281 - mae: 5.4281\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3942 - mae: 5.3942\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.3536 - mae: 5.3536\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.4880 - mae: 5.4880\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1658 - mae: 5.1658\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6283 - mae: 5.6283\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4548 - mae: 5.4548\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 5.1168 - mae: 5.1168\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.8497 - mae: 4.8497\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9694 - mae: 4.9694\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9671 - mae: 4.9671\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 4.7750 - mae: 4.7750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a59b1a310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us5skbJRciMG",
        "outputId": "c7aa21b5-5f71-48bd-af79-a777b8bc3584"
      },
      "source": [
        "model_5.evaluate(X_test,y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4a5919d290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 12.6271 - mae: 12.6271\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12.627066612243652, 12.627066612243652]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXpnJBFQcqYp",
        "outputId": "1819c7b4-1008-46fd-fd54-d98cf39896f6"
      },
      "source": [
        "# What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "#model_6\n",
        "\n",
        "# Create a model\n",
        "model_6 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_6.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_6.fit(X_train,y_train,epochs=200)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 40.8011 - mae: 40.8011\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 36.5624 - mae: 36.5624\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.7383 - mae: 32.7383\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 28.7189 - mae: 28.7189\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.6893 - mae: 23.6893\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.0024 - mae: 20.0024\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.7660 - mae: 15.7660\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.7536 - mae: 11.7536\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 8.3074 - mae: 8.3074\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.6261 - mae: 8.6261\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2860 - mae: 10.2860\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1830 - mae: 11.1830\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.5607 - mae: 11.5607\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.2802 - mae: 11.2802\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6450 - mae: 10.6450\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.8570 - mae: 9.8570\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8856 - mae: 8.8856\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8299 - mae: 7.8299\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3602 - mae: 7.3602\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3105 - mae: 8.3105\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.7104 - mae: 8.7104\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2573 - mae: 8.2573\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2296 - mae: 8.2296\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7435 - mae: 7.7435\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1341 - mae: 7.1341\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3123 - mae: 7.3123\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0560 - mae: 8.0560\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9716 - mae: 7.9716\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5142 - mae: 7.5142\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.1506 - mae: 7.1506\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.3071 - mae: 7.3071\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5453 - mae: 7.5453\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5611 - mae: 7.5611\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9934 - mae: 6.9934\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0507 - mae: 7.0507\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3199 - mae: 7.3199\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4209 - mae: 7.4209\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0677 - mae: 7.0677\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9647 - mae: 6.9647\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.0829 - mae: 7.0829\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0148 - mae: 7.0148\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9188 - mae: 6.9188\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7968 - mae: 6.7968\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.9892 - mae: 6.9892\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9643 - mae: 6.9643\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6329 - mae: 6.6329\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7048 - mae: 6.7048\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5209 - mae: 6.5209\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5993 - mae: 6.5993\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.6929 - mae: 6.6929\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.6689 - mae: 6.6689\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5923 - mae: 6.5923\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5084 - mae: 6.5084\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5314 - mae: 6.5314\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3270 - mae: 6.3270\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.4422 - mae: 6.4422\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5362 - mae: 6.5362\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3347 - mae: 6.3347\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.3432 - mae: 6.3432\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5218 - mae: 6.5218\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2740 - mae: 6.2740\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.5459 - mae: 6.5459\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.2640 - mae: 6.2640\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2959 - mae: 6.2959\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1754 - mae: 6.1754\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.1835 - mae: 6.1835\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2072 - mae: 6.2072\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.0905 - mae: 6.0905\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0056 - mae: 6.0056\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0975 - mae: 6.0975\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.0576 - mae: 6.0576\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8747 - mae: 5.8747\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.0011 - mae: 6.0011\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.8270 - mae: 5.8270\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.8259 - mae: 5.8259\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.8573 - mae: 5.8573\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.6715 - mae: 5.6715\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7468 - mae: 5.7468\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6975 - mae: 5.6975\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.5742 - mae: 5.5742\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7569 - mae: 5.7569\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7597 - mae: 5.7597\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.5893 - mae: 5.5893\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4062 - mae: 5.4062\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3507 - mae: 5.3507\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4925 - mae: 5.4925\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 5.3863 - mae: 5.3863\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.4957 - mae: 5.4957\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2740 - mae: 5.2740\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.5235 - mae: 5.5235\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1475 - mae: 5.1475\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4651 - mae: 5.4651\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.2845 - mae: 5.2845\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.3121 - mae: 5.3121\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3320 - mae: 5.3320\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1522 - mae: 5.1522\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.1324 - mae: 5.1324\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.2750 - mae: 5.2750\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.8335 - mae: 4.8335\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.1326 - mae: 5.1326\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.1062 - mae: 5.1062\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.7447 - mae: 4.7447\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.0394 - mae: 5.0394\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6998 - mae: 4.6998\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8228 - mae: 4.8228\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.9577 - mae: 4.9577\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.3209 - mae: 4.3209\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8337 - mae: 4.8337\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9390 - mae: 4.9390\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.4960 - mae: 4.4960\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.3525 - mae: 4.3525\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5858 - mae: 4.5858\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 4.0549 - mae: 4.0549\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.5414 - mae: 4.5414\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.7613 - mae: 4.7613\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.3156 - mae: 4.3156\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.8087 - mae: 3.8087\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 4.1531 - mae: 4.1531\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.8549 - mae: 3.8549\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.8050 - mae: 3.8050\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.0767 - mae: 4.0767\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7024 - mae: 3.7024\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5383 - mae: 3.5383\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3213 - mae: 3.3213\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4709 - mae: 3.4709\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3550 - mae: 3.3550\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.9890 - mae: 2.9890\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.9851 - mae: 2.9851\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.8484 - mae: 2.8484\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.8741 - mae: 2.8741\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.7787 - mae: 2.7787\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.6182 - mae: 2.6182\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.5195 - mae: 2.5195\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.3156 - mae: 2.3156\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.3118 - mae: 2.3118\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.2047 - mae: 2.2047\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 2.1028 - mae: 2.1028\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.9490 - mae: 1.9490\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.8246 - mae: 1.8246\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 1.6782 - mae: 1.6782\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.6004 - mae: 1.6004\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5890 - mae: 1.5890\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3025 - mae: 1.3025\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.9788 - mae: 1.9788\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3303 - mae: 1.3303\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.8988 - mae: 1.8988\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.0137 - mae: 2.0137\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7467 - mae: 0.7467\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2804 - mae: 1.2804\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9341 - mae: 0.9341\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.8905 - mae: 0.8905\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7930 - mae: 0.7930\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6975 - mae: 0.6975\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.3637 - mae: 0.3637\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.2049 - mae: 1.2049\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.8042 - mae: 0.8042\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7698 - mae: 0.7698\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7445 - mae: 0.7445\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6948 - mae: 0.6948\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4144 - mae: 0.4144\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6265 - mae: 1.6265\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7420 - mae: 0.7420\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5595 - mae: 0.5595\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 1.0272 - mae: 1.0272\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.9706 - mae: 0.9706\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.0824 - mae: 1.0824\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.8894 - mae: 0.8894\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9415 - mae: 0.9415\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5935 - mae: 0.5935\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9743 - mae: 0.9743\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1818 - mae: 0.1818\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0686 - mae: 1.0686\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1929 - mae: 0.1929\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.3529 - mae: 0.3529\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2148 - mae: 0.2148\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6016 - mae: 0.6016\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2542 - mae: 0.2542\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1856 - mae: 1.1856\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1104 - mae: 0.1104\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1008 - mae: 1.1008\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0635 - mae: 0.0635\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0855 - mae: 0.0855\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1347 - mae: 0.1347\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1188 - mae: 0.1188\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2637 - mae: 0.2637\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4799 - mae: 0.4799\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1427 - mae: 0.1427\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2291 - mae: 0.2291\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7226 - mae: 0.7226\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4011 - mae: 0.4011\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9125 - mae: 0.9125\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1151 - mae: 0.1151\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0243 - mae: 1.0243\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1811 - mae: 0.1811\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6682 - mae: 1.6682\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8619 - mae: 0.8619\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6834 - mae: 0.6834\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2992 - mae: 0.2992\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0965 - mae: 1.0965\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.2518 - mae: 0.2518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4a57792250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkHb4aZMc5bY",
        "outputId": "f146243d-8167-4656-8d84-16b9a564a1c9"
      },
      "source": [
        "model_6.evaluate(X_test,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7f4a576979e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 2.8587 - mae: 2.8587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.858712673187256, 2.858712673187256]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heTTDjEJeHTK"
      },
      "source": [
        "## Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDzJvi8yc8yk"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}