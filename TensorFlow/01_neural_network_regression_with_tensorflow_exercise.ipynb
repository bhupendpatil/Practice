{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow_exercise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPaxAsUFqsPA"
      },
      "source": [
        "# **ðŸ›  01 Neural network regression with TensorFlow Exercises**\n",
        "[Source](https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises)\n",
        "\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "\n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibdLN72aRSD6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL51hb3NZLMR"
      },
      "source": [
        "## 1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nr84c7SFcsU"
      },
      "source": [
        "# Create dataset\n",
        "X = tf.range(-100,100,4)\n",
        "y = X + 10"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mJ7kIzj7RvHf",
        "outputId": "0f123f62-3c75-43b9-becc-a19c7eadb373"
      },
      "source": [
        "plt.scatter(X,y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe8a06dba10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrSagkZbu1Z",
        "outputId": "c48e3cc7-d25b-44f1-f5fe-ac4e0f15434e"
      },
      "source": [
        "X,y"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "          32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "          76,   80,   84,   88,   92,   96], dtype=int32)>,\n",
              " <tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "         66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ7C2pbyZ6Oo"
      },
      "source": [
        "# Splitting data into train and test sets\n",
        "X_train = X[:40] \n",
        "X_test = X[40:] \n",
        "y_train = y[:40] \n",
        "y_test = y[40:]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmm78ICIR74F",
        "outputId": "734ad718-46b9-42b3-f265-fc60d2001233"
      },
      "source": [
        "# model_1\n",
        "\n",
        "# Create a model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_1.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_1.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 3s 7ms/step - loss: 44.0170 - mae: 44.0170\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 40.8826 - mae: 40.8826\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 38.4906 - mae: 38.4906\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 34.6945 - mae: 34.6945\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.9193 - mae: 31.9193\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 27.8055 - mae: 27.8055\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 25.0270 - mae: 25.0270\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.2639 - mae: 22.2639\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.7198 - mae: 19.7198\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.9335 - mae: 16.9335\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 15.2059 - mae: 15.2059\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.4738 - mae: 13.4738\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.2786 - mae: 12.2786\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.1104 - mae: 11.1104\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0031 - mae: 10.0031\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3101 - mae: 9.3101\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5856 - mae: 8.5856\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9845 - mae: 7.9845\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8526 - mae: 7.8526\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0104 - mae: 8.0104\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6298 - mae: 7.6298\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4114 - mae: 7.4114\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6550 - mae: 7.6550\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5859 - mae: 7.5859\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7394 - mae: 7.7394\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9743 - mae: 7.9743\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1723 - mae: 8.1723\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.5936 - mae: 7.5936\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4734 - mae: 7.4734\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7440 - mae: 7.7440\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.8424 - mae: 7.8424\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8222 - mae: 7.8222\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8718 - mae: 7.8718\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.7663 - mae: 7.7663\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9011 - mae: 7.9011\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6352 - mae: 7.6352\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6332 - mae: 7.6332\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5155 - mae: 7.5155\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4128 - mae: 7.4128\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3223 - mae: 7.3223\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5082 - mae: 7.5082\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8527 - mae: 7.8527\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6331 - mae: 7.6331\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6457 - mae: 7.6457\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6879 - mae: 7.6879\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9840 - mae: 7.9840\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6396 - mae: 7.6396\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6026 - mae: 7.6026\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7835 - mae: 7.7835\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5651 - mae: 7.5651\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9813 - mae: 7.9813\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5699 - mae: 7.5699\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.5433 - mae: 7.5433\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4655 - mae: 7.4655\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5957 - mae: 7.5957\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.6799 - mae: 7.6799\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4578 - mae: 7.4578\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.6949 - mae: 7.6949\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.5939 - mae: 7.5939\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7420 - mae: 7.7420\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4996 - mae: 7.4996\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2755 - mae: 7.2755\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8948 - mae: 7.8948\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.8044 - mae: 7.8044\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6114 - mae: 7.6114\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6648 - mae: 7.6648\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8547 - mae: 7.8547\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6838 - mae: 7.6838\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7320 - mae: 7.7320\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5435 - mae: 7.5435\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7673 - mae: 7.7673\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5765 - mae: 7.5765\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.9838 - mae: 7.9838\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0141 - mae: 8.0141\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.5938 - mae: 7.5938\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4648 - mae: 7.4648\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7195 - mae: 7.7195\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2185 - mae: 7.2185\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.5170 - mae: 7.5170\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3999 - mae: 7.3999\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5832 - mae: 7.5832\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.7442 - mae: 7.7442\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6300 - mae: 7.6300\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5568 - mae: 7.5568\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6737 - mae: 7.6737\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5906 - mae: 7.5906\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8614 - mae: 7.8614\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5220 - mae: 7.5220\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.4057 - mae: 7.4057\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6387 - mae: 7.6387\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6957 - mae: 7.6957\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5229 - mae: 7.5229\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7601 - mae: 7.7601\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.8403 - mae: 7.8403\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.1905 - mae: 8.1905\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.0742 - mae: 8.0742\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8269 - mae: 7.8269\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4432 - mae: 7.4432\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 7.5032 - mae: 7.5032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8b086d8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQY5Tspgefve",
        "outputId": "02f73658-7716-4622-e450-ee6922a26532"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                20        \n",
            "=================================================================\n",
            "Total params: 20\n",
            "Trainable params: 20\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa0TpHTdy8H"
      },
      "source": [
        "## 2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l8rGvb1ccMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3918723a-fd16-4046-a048-6beb7c599d4a"
      },
      "source": [
        "# model_2\n",
        "\n",
        "# Create a model\n",
        "model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model_2.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# Fit a model\n",
        "model_2.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.8536 - mae: 21.8536\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.1309 - mae: 18.1309\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.9710 - mae: 13.9710\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1232 - mae: 10.1232\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9384 - mae: 7.9384\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1541 - mae: 9.1541\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2733 - mae: 10.2733\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5547 - mae: 10.5547\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1337 - mae: 10.1337\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.4421 - mae: 9.4421\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3478 - mae: 8.3478\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6363 - mae: 7.6363\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9715 - mae: 7.9715\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3389 - mae: 8.3389\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3351 - mae: 8.3351\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6582 - mae: 7.6582\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4592 - mae: 7.4592\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9026 - mae: 7.9026\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9392 - mae: 7.9392\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8027 - mae: 7.8027\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.2910 - mae: 7.2910\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4137 - mae: 7.4137\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4159 - mae: 7.4159\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5757 - mae: 7.5757\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.5434 - mae: 7.5434\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3361 - mae: 7.3361\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3115 - mae: 7.3115\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1775 - mae: 7.1775\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1226 - mae: 7.1226\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1308 - mae: 7.1308\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1723 - mae: 7.1723\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0702 - mae: 7.0702\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.9798 - mae: 6.9798\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 6.8678 - mae: 6.8678\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8190 - mae: 6.8190\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8370 - mae: 6.8370\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.9543 - mae: 6.9543\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7981 - mae: 6.7981\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 6.6506 - mae: 6.6506\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.8749 - mae: 6.8749\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.6610 - mae: 6.6610\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.7811 - mae: 6.7811\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.7573 - mae: 6.7573\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.6388 - mae: 6.6388\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5247 - mae: 6.5247\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7099 - mae: 6.7099\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.5696 - mae: 6.5696\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5745 - mae: 6.5745\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.8416 - mae: 6.8416\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.5471 - mae: 6.5471\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3360 - mae: 6.3360\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3964 - mae: 6.3964\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5660 - mae: 6.5660\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3832 - mae: 6.3832\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.2984 - mae: 6.2984\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4168 - mae: 6.4168\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.3839 - mae: 6.3839\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.6421 - mae: 6.6421\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.5144 - mae: 6.5144\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.2239 - mae: 6.2239\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.4159 - mae: 6.4159\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.3960 - mae: 6.3960\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.2335 - mae: 6.2335\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.9667 - mae: 5.9667\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.3298 - mae: 6.3298\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0392 - mae: 6.0392\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.1226 - mae: 6.1226\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9082 - mae: 5.9082\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.0220 - mae: 6.0220\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.7006 - mae: 5.7006\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6800 - mae: 5.6800\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9361 - mae: 5.9361\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.9037 - mae: 5.9037\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.6939 - mae: 5.6939\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.6023 - mae: 5.6023\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4208 - mae: 5.4208\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.4410 - mae: 5.4410\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.3937 - mae: 5.3937\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4578 - mae: 5.4578\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.3424 - mae: 5.3424\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2607 - mae: 5.2607\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.4293 - mae: 5.4293\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.2594 - mae: 5.2594\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 5.1864 - mae: 5.1864\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.2188 - mae: 5.2188\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 5.1109 - mae: 5.1109\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.0396 - mae: 5.0396\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 5.0129 - mae: 5.0129\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 4.8987 - mae: 4.8987\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.8355 - mae: 4.8355\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.7690 - mae: 4.7690\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.8421 - mae: 4.8421\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.6483 - mae: 4.6483\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 4.5814 - mae: 4.5814\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8250 - mae: 4.8250\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.8456 - mae: 4.8456\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5604 - mae: 4.5604\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.6773 - mae: 4.6773\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.5332 - mae: 4.5332\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 4.3174 - mae: 4.3174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe864165c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrA8P9PXRizl",
        "outputId": "48f30032-f1f3-48c2-8298-e1a30ebd5488"
      },
      "source": [
        "model_1.evaluate(X_test,y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 104ms/step - loss: 18.8028 - mae: 18.8028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[18.802845001220703, 18.802845001220703]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFZqh8x-SAF3",
        "outputId": "2bf16caa-2f49-44b6-8c6c-da7f25483e4e"
      },
      "source": [
        "model_2.evaluate(X_test,y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 96ms/step - loss: 9.2291 - mae: 9.2291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.22912883758545, 9.22912883758545]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INiX8XI2ZKNd"
      },
      "source": [
        "model_1 loss is 18.4417 and model_2 loss is 12.3388, model_2 performs bit well than model_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz2YvwscZuUP"
      },
      "source": [
        "## 3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "* Building a larger model (how does one with 4 dense layers go?).\n",
        "* Increasing the number of units in each layer.\n",
        "* Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "* What happens if you train for longer (say 300 epochs instead of 200)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPU36I3cmBNl"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8az4YJexKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f8355826-a62b-4e22-a9b1-d95fed27dfc2"
      },
      "source": [
        "# insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "FVmavYkamZso",
        "outputId": "458af155-6ea7-40bd-afcf-dcba07fa5a5b"
      },
      "source": [
        "# one hot encoding\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9Lba4pvszca"
      },
      "source": [
        "# Create X and y\n",
        "X = insurance_one_hot.drop(\"charges\",axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOr0IhbMtAjV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eFFp56otZfc",
        "outputId": "3048aa2e-6930-4e7a-dc5b-23c23753bf9d"
      },
      "source": [
        "# Building a larger model (how does one with 4 dense layers go?).\n",
        "# model_3\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_3.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "model_3.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe864030750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpaOUGhJuRYG",
        "outputId": "d07e133f-50ff-4d1e-e8cc-8c489aba0cf3"
      },
      "source": [
        "model_3.evaluate(X_test,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[nan, nan]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OWnS1YUuZbq"
      },
      "source": [
        "Output shows nan on 4 layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mVt7xh0uf8y",
        "outputId": "fab1f817-9989-4196-ebeb-6aa943e844b1"
      },
      "source": [
        "# Increasing the number of units in each layer.\n",
        "# model_4\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_4 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_4.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "model_4.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe852692c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKcQ8oSdu1fR",
        "outputId": "8a535f1b-482a-4ca9-e70a-544ca0a745b9"
      },
      "source": [
        "# Lookup the documentation of Adam and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "# model_5\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_5.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "model_5.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13279.2569 - mae: 13279.2569\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12783.3752 - mae: 12783.3752\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12010.6525 - mae: 12010.6525\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11049.8789 - mae: 11049.8789\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 8279.7633 - mae: 8279.7633\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7559.1312 - mae: 7559.1312\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7407.2942 - mae: 7407.2942\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7464.1331 - mae: 7464.1331\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7434.3430 - mae: 7434.3430\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7531.2869 - mae: 7531.2869\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7674.0843 - mae: 7674.0843\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7217.4238 - mae: 7217.4238\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7483.8767 - mae: 7483.8767\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7209.2060 - mae: 7209.2060\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7441.8390 - mae: 7441.8390\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7335.4630 - mae: 7335.4630\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6659.0678 - mae: 6659.0678\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6841.8470 - mae: 6841.8470\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6808.4471 - mae: 6808.4471\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6730.3521 - mae: 6730.3521\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6051.9020 - mae: 6051.9020\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6210.4943 - mae: 6210.4943\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6625.5053 - mae: 6625.5053\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6301.2079 - mae: 6301.2079\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7012.4547 - mae: 7012.4547\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6162.0445 - mae: 6162.0445\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6545.8055 - mae: 6545.8055\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6830.9490 - mae: 6830.9490\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6094.6122 - mae: 6094.6122\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6594.2145 - mae: 6594.2145\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0363 - mae: 6884.0363\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6304.9636 - mae: 6304.9636\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6434.1088 - mae: 6434.1088\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6316.5356 - mae: 6316.5356\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6394.9598 - mae: 6394.9598\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6227.9476 - mae: 6227.9476\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.4009 - mae: 6428.4009\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5913.4456 - mae: 5913.4456\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6326.5346 - mae: 6326.5346\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6216.1019 - mae: 6216.1019\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6162.1463 - mae: 6162.1463\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6037.3755 - mae: 6037.3755\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6044.3418 - mae: 6044.3418\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5790.0280 - mae: 5790.0280\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5804.0101 - mae: 5804.0101\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5562.9877 - mae: 5562.9877\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6061.1883 - mae: 6061.1883\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5732.2305 - mae: 5732.2305\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5440.9832 - mae: 5440.9832\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5637.7700 - mae: 5637.7700\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5508.5509 - mae: 5508.5509\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5426.3935 - mae: 5426.3935\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5028.6428 - mae: 5028.6428\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5314.5327 - mae: 5314.5327\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4980.0836 - mae: 4980.0836\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4885.9996 - mae: 4885.9996\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5062.7607 - mae: 5062.7607\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4623.5893 - mae: 4623.5893\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4191.9043 - mae: 4191.9043\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4215.4012 - mae: 4215.4012\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4266.0303 - mae: 4266.0303\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4138.2351 - mae: 4138.2351\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4061.8892 - mae: 4061.8892\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3768.2783 - mae: 3768.2783\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3836.0356 - mae: 3836.0356\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.3567 - mae: 3638.3567\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.6901 - mae: 3758.6901\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3768.8844 - mae: 3768.8844\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3963.3639 - mae: 3963.3639\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3588.2938 - mae: 3588.2938\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3768.4698 - mae: 3768.4698\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3549.3439 - mae: 3549.3439\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3916.9308 - mae: 3916.9308\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3815.6833 - mae: 3815.6833\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4062.3997 - mae: 4062.3997\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3616.9545 - mae: 3616.9545\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3893.2896 - mae: 3893.2896\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.2550 - mae: 3613.2550\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3310.9478 - mae: 3310.9478\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3416.4976 - mae: 3416.4976\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3650.5401 - mae: 3650.5401\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4171.0960 - mae: 4171.0960\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3773.2784 - mae: 3773.2784\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3606.9250 - mae: 3606.9250\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3257.9806 - mae: 3257.9806\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.7799 - mae: 3765.7799\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3656.5695 - mae: 3656.5695\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3780.4494 - mae: 3780.4494\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3496.4630 - mae: 3496.4630\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3863.0515 - mae: 3863.0515\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.5496 - mae: 3713.5496\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.6711 - mae: 3794.6711\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3566.1044 - mae: 3566.1044\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.1822 - mae: 3479.1822\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.2047 - mae: 3636.2047\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3840.6174 - mae: 3840.6174\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3502.4618 - mae: 3502.4618\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.6499 - mae: 3508.6499\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3284.7367 - mae: 3284.7367\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.3045 - mae: 3501.3045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8525efd90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suoGbFWDvDAl",
        "outputId": "9550a988-6b29-40ff-d311-395a6cdbf4c2"
      },
      "source": [
        "# What happens if you train for longer (say 300 epochs instead of 200)?\n",
        "# model_6\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_6.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "model_6.fit(X_train,y_train,epochs=300)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13279.2569 - mae: 13279.2569\n",
            "Epoch 2/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12783.3752 - mae: 12783.3752\n",
            "Epoch 3/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12010.6525 - mae: 12010.6525\n",
            "Epoch 4/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11049.8789 - mae: 11049.8789\n",
            "Epoch 5/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8279.7633 - mae: 8279.7633\n",
            "Epoch 6/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7559.1312 - mae: 7559.1312\n",
            "Epoch 7/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7407.2942 - mae: 7407.2942\n",
            "Epoch 8/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7464.1331 - mae: 7464.1331\n",
            "Epoch 9/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7434.3430 - mae: 7434.3430\n",
            "Epoch 10/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7531.2869 - mae: 7531.2869\n",
            "Epoch 11/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7674.0843 - mae: 7674.0843\n",
            "Epoch 12/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7217.4238 - mae: 7217.4238\n",
            "Epoch 13/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7483.8770 - mae: 7483.8770\n",
            "Epoch 14/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7209.2059 - mae: 7209.2059\n",
            "Epoch 15/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7441.8390 - mae: 7441.8390\n",
            "Epoch 16/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7335.4630 - mae: 7335.4630\n",
            "Epoch 17/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6659.0677 - mae: 6659.0677\n",
            "Epoch 18/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6841.8470 - mae: 6841.8470\n",
            "Epoch 19/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6808.4472 - mae: 6808.4472\n",
            "Epoch 20/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6730.3521 - mae: 6730.3521\n",
            "Epoch 21/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6051.9016 - mae: 6051.9016\n",
            "Epoch 22/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6210.4945 - mae: 6210.4945\n",
            "Epoch 23/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6625.5053 - mae: 6625.5053\n",
            "Epoch 24/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6301.2081 - mae: 6301.2081\n",
            "Epoch 25/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7012.4547 - mae: 7012.4547\n",
            "Epoch 26/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6162.0440 - mae: 6162.0440\n",
            "Epoch 27/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6545.8055 - mae: 6545.8055\n",
            "Epoch 28/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6830.9490 - mae: 6830.9490\n",
            "Epoch 29/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6094.6116 - mae: 6094.6116\n",
            "Epoch 30/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6594.2143 - mae: 6594.2143\n",
            "Epoch 31/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0363 - mae: 6884.0363\n",
            "Epoch 32/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6304.9635 - mae: 6304.9635\n",
            "Epoch 33/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6434.1088 - mae: 6434.1088\n",
            "Epoch 34/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6316.5355 - mae: 6316.5355\n",
            "Epoch 35/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6394.9598 - mae: 6394.9598\n",
            "Epoch 36/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6227.9477 - mae: 6227.9477\n",
            "Epoch 37/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.4009 - mae: 6428.4009\n",
            "Epoch 38/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5913.4462 - mae: 5913.4462\n",
            "Epoch 39/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6326.5346 - mae: 6326.5346\n",
            "Epoch 40/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6216.1019 - mae: 6216.1019\n",
            "Epoch 41/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6162.1463 - mae: 6162.1463\n",
            "Epoch 42/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6037.3756 - mae: 6037.3756\n",
            "Epoch 43/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6044.3418 - mae: 6044.3418\n",
            "Epoch 44/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5790.0279 - mae: 5790.0279\n",
            "Epoch 45/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5804.0100 - mae: 5804.0100\n",
            "Epoch 46/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5562.9877 - mae: 5562.9877\n",
            "Epoch 47/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6061.1883 - mae: 6061.1883\n",
            "Epoch 48/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5732.2307 - mae: 5732.2307\n",
            "Epoch 49/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5440.9834 - mae: 5440.9834\n",
            "Epoch 50/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5637.7701 - mae: 5637.7701\n",
            "Epoch 51/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5508.5509 - mae: 5508.5509\n",
            "Epoch 52/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5426.3933 - mae: 5426.3933\n",
            "Epoch 53/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5028.6428 - mae: 5028.6428\n",
            "Epoch 54/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5314.5325 - mae: 5314.5325\n",
            "Epoch 55/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4980.0834 - mae: 4980.0834\n",
            "Epoch 56/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4885.9993 - mae: 4885.9993\n",
            "Epoch 57/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5062.7606 - mae: 5062.7606\n",
            "Epoch 58/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4623.5892 - mae: 4623.5892\n",
            "Epoch 59/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4191.9044 - mae: 4191.9044\n",
            "Epoch 60/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4215.4012 - mae: 4215.4012\n",
            "Epoch 61/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4266.0303 - mae: 4266.0303\n",
            "Epoch 62/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4138.2350 - mae: 4138.2350\n",
            "Epoch 63/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4061.8894 - mae: 4061.8894\n",
            "Epoch 64/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3768.2780 - mae: 3768.2780\n",
            "Epoch 65/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3836.0357 - mae: 3836.0357\n",
            "Epoch 66/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.3568 - mae: 3638.3568\n",
            "Epoch 67/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.6906 - mae: 3758.6906\n",
            "Epoch 68/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3768.8845 - mae: 3768.8845\n",
            "Epoch 69/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3963.3639 - mae: 3963.3639\n",
            "Epoch 70/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3588.2939 - mae: 3588.2939\n",
            "Epoch 71/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3768.4698 - mae: 3768.4698\n",
            "Epoch 72/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3549.3438 - mae: 3549.3438\n",
            "Epoch 73/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3916.9309 - mae: 3916.9309\n",
            "Epoch 74/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3815.6833 - mae: 3815.6833\n",
            "Epoch 75/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4062.3997 - mae: 4062.3997\n",
            "Epoch 76/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3616.9546 - mae: 3616.9546\n",
            "Epoch 77/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3893.2896 - mae: 3893.2896\n",
            "Epoch 78/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3613.2550 - mae: 3613.2550\n",
            "Epoch 79/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3310.9477 - mae: 3310.9477\n",
            "Epoch 80/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3416.4976 - mae: 3416.4976\n",
            "Epoch 81/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3650.5400 - mae: 3650.5400\n",
            "Epoch 82/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4171.0959 - mae: 4171.0959\n",
            "Epoch 83/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3773.2785 - mae: 3773.2785\n",
            "Epoch 84/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3606.9251 - mae: 3606.9251\n",
            "Epoch 85/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3257.9805 - mae: 3257.9805\n",
            "Epoch 86/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3765.7800 - mae: 3765.7800\n",
            "Epoch 87/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3656.5694 - mae: 3656.5694\n",
            "Epoch 88/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3780.4494 - mae: 3780.4494\n",
            "Epoch 89/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3496.4629 - mae: 3496.4629\n",
            "Epoch 90/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3863.0516 - mae: 3863.0516\n",
            "Epoch 91/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.5495 - mae: 3713.5495\n",
            "Epoch 92/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.6712 - mae: 3794.6712\n",
            "Epoch 93/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3566.1044 - mae: 3566.1044\n",
            "Epoch 94/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3479.1821 - mae: 3479.1821\n",
            "Epoch 95/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.2045 - mae: 3636.2045\n",
            "Epoch 96/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3840.6172 - mae: 3840.6172\n",
            "Epoch 97/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3502.4616 - mae: 3502.4616\n",
            "Epoch 98/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.6495 - mae: 3508.6495\n",
            "Epoch 99/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3284.7366 - mae: 3284.7366\n",
            "Epoch 100/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3501.3044 - mae: 3501.3044\n",
            "Epoch 101/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3587.2210 - mae: 3587.2210\n",
            "Epoch 102/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3511.4476 - mae: 3511.4476\n",
            "Epoch 103/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3292.8795 - mae: 3292.8795\n",
            "Epoch 104/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3760.2491 - mae: 3760.2491\n",
            "Epoch 105/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3495.5974 - mae: 3495.5974\n",
            "Epoch 106/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3666.5520 - mae: 3666.5520\n",
            "Epoch 107/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3814.6443 - mae: 3814.6443\n",
            "Epoch 108/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3641.1751 - mae: 3641.1751\n",
            "Epoch 109/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3869.5878 - mae: 3869.5878\n",
            "Epoch 110/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3965.0898 - mae: 3965.0898\n",
            "Epoch 111/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3847.0503 - mae: 3847.0503\n",
            "Epoch 112/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3574.0113 - mae: 3574.0113\n",
            "Epoch 113/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.6265 - mae: 3624.6265\n",
            "Epoch 114/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3790.4027 - mae: 3790.4027\n",
            "Epoch 115/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3612.7208 - mae: 3612.7208\n",
            "Epoch 116/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3875.8088 - mae: 3875.8088\n",
            "Epoch 117/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3577.3801 - mae: 3577.3801\n",
            "Epoch 118/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3578.5728 - mae: 3578.5728\n",
            "Epoch 119/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.0352 - mae: 3687.0352\n",
            "Epoch 120/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3823.1660 - mae: 3823.1660\n",
            "Epoch 121/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3839.3489 - mae: 3839.3489\n",
            "Epoch 122/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3645.7999 - mae: 3645.7999\n",
            "Epoch 123/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.6499 - mae: 3516.6499\n",
            "Epoch 124/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3463.7250 - mae: 3463.7250\n",
            "Epoch 125/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3731.9607 - mae: 3731.9607\n",
            "Epoch 126/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3644.1352 - mae: 3644.1352\n",
            "Epoch 127/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3633.8461 - mae: 3633.8461\n",
            "Epoch 128/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3586.9452 - mae: 3586.9452\n",
            "Epoch 129/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3712.0534 - mae: 3712.0534\n",
            "Epoch 130/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3614.7115 - mae: 3614.7115\n",
            "Epoch 131/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3444.4037 - mae: 3444.4037\n",
            "Epoch 132/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3846.8537 - mae: 3846.8537\n",
            "Epoch 133/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.7436 - mae: 3705.7436\n",
            "Epoch 134/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3717.1137 - mae: 3717.1137\n",
            "Epoch 135/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3553.4536 - mae: 3553.4536\n",
            "Epoch 136/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3530.2701 - mae: 3530.2701\n",
            "Epoch 137/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3411.2901 - mae: 3411.2901\n",
            "Epoch 138/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3777.0426 - mae: 3777.0426\n",
            "Epoch 139/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3459.6291 - mae: 3459.6291\n",
            "Epoch 140/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3619.1610 - mae: 3619.1610\n",
            "Epoch 141/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3919.3606 - mae: 3919.3606\n",
            "Epoch 142/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.8529 - mae: 3532.8529\n",
            "Epoch 143/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.7953 - mae: 3516.7953\n",
            "Epoch 144/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.8465 - mae: 3680.8465\n",
            "Epoch 145/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3852.0211 - mae: 3852.0211\n",
            "Epoch 146/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3573.1808 - mae: 3573.1808\n",
            "Epoch 147/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3717.6648 - mae: 3717.6648\n",
            "Epoch 148/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3624.8275 - mae: 3624.8275\n",
            "Epoch 149/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3377.4241 - mae: 3377.4241\n",
            "Epoch 150/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3689.1892 - mae: 3689.1892\n",
            "Epoch 151/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3621.7334 - mae: 3621.7334\n",
            "Epoch 152/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3491.8533 - mae: 3491.8533\n",
            "Epoch 153/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3428.6129 - mae: 3428.6129\n",
            "Epoch 154/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.5403 - mae: 3691.5403\n",
            "Epoch 155/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3430.7736 - mae: 3430.7736\n",
            "Epoch 156/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3420.3126 - mae: 3420.3126\n",
            "Epoch 157/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3328.2781 - mae: 3328.2781\n",
            "Epoch 158/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3610.6989 - mae: 3610.6989\n",
            "Epoch 159/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3427.5754 - mae: 3427.5754\n",
            "Epoch 160/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.7259 - mae: 3519.7259\n",
            "Epoch 161/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3449.7549 - mae: 3449.7549\n",
            "Epoch 162/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3503.6291 - mae: 3503.6291\n",
            "Epoch 163/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3424.0201 - mae: 3424.0201\n",
            "Epoch 164/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3516.4030 - mae: 3516.4030\n",
            "Epoch 165/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3363.9656 - mae: 3363.9656\n",
            "Epoch 166/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.6178 - mae: 3638.6178\n",
            "Epoch 167/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3674.3195 - mae: 3674.3195\n",
            "Epoch 168/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3650.9425 - mae: 3650.9425\n",
            "Epoch 169/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3431.0297 - mae: 3431.0297\n",
            "Epoch 170/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3807.0788 - mae: 3807.0788\n",
            "Epoch 171/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3592.2753 - mae: 3592.2753\n",
            "Epoch 172/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3622.6392 - mae: 3622.6392\n",
            "Epoch 173/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.5097 - mae: 3716.5097\n",
            "Epoch 174/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3386.2161 - mae: 3386.2161\n",
            "Epoch 175/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.9057 - mae: 3693.9057\n",
            "Epoch 176/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.7093 - mae: 3680.7093\n",
            "Epoch 177/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3508.4842 - mae: 3508.4842\n",
            "Epoch 178/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3767.8639 - mae: 3767.8639\n",
            "Epoch 179/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3263.3626 - mae: 3263.3626\n",
            "Epoch 180/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3668.2400 - mae: 3668.2400\n",
            "Epoch 181/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3750.7590 - mae: 3750.7590\n",
            "Epoch 182/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3576.5514 - mae: 3576.5514\n",
            "Epoch 183/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3321.3290 - mae: 3321.3290\n",
            "Epoch 184/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3380.9050 - mae: 3380.9050\n",
            "Epoch 185/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3294.3915 - mae: 3294.3915\n",
            "Epoch 186/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3664.9207 - mae: 3664.9207\n",
            "Epoch 187/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3621.4873 - mae: 3621.4873\n",
            "Epoch 188/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3481.8285 - mae: 3481.8285\n",
            "Epoch 189/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3290.3885 - mae: 3290.3885\n",
            "Epoch 190/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3574.5210 - mae: 3574.5210\n",
            "Epoch 191/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3362.1313 - mae: 3362.1313\n",
            "Epoch 192/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3352.7548 - mae: 3352.7548\n",
            "Epoch 193/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3394.4173 - mae: 3394.4173\n",
            "Epoch 194/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3680.7325 - mae: 3680.7325\n",
            "Epoch 195/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3378.8527 - mae: 3378.8527\n",
            "Epoch 196/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3343.8965 - mae: 3343.8965\n",
            "Epoch 197/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3651.1711 - mae: 3651.1711\n",
            "Epoch 198/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3215.4661 - mae: 3215.4661\n",
            "Epoch 199/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3558.4236 - mae: 3558.4236\n",
            "Epoch 200/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.3026 - mae: 3672.3026\n",
            "Epoch 201/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3485.4850 - mae: 3485.4850\n",
            "Epoch 202/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3612.8396 - mae: 3612.8396\n",
            "Epoch 203/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4004.6541 - mae: 4004.6541\n",
            "Epoch 204/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3532.7280 - mae: 3532.7280\n",
            "Epoch 205/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3380.0120 - mae: 3380.0120\n",
            "Epoch 206/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3701.8380 - mae: 3701.8380\n",
            "Epoch 207/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3459.1263 - mae: 3459.1263\n",
            "Epoch 208/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3366.1594 - mae: 3366.1594\n",
            "Epoch 209/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3482.5424 - mae: 3482.5424\n",
            "Epoch 210/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3601.7335 - mae: 3601.7335\n",
            "Epoch 211/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3438.6261 - mae: 3438.6261\n",
            "Epoch 212/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3354.0643 - mae: 3354.0643\n",
            "Epoch 213/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3259.9498 - mae: 3259.9498\n",
            "Epoch 214/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3359.9861 - mae: 3359.9861\n",
            "Epoch 215/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3513.0050 - mae: 3513.0050\n",
            "Epoch 216/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3611.6427 - mae: 3611.6427\n",
            "Epoch 217/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3477.4683 - mae: 3477.4683\n",
            "Epoch 218/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3331.4948 - mae: 3331.4948\n",
            "Epoch 219/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3684.4303 - mae: 3684.4303\n",
            "Epoch 220/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3519.0516 - mae: 3519.0516\n",
            "Epoch 221/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3379.6767 - mae: 3379.6767\n",
            "Epoch 222/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.9060 - mae: 3687.9060\n",
            "Epoch 223/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3418.0075 - mae: 3418.0075\n",
            "Epoch 224/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.5666 - mae: 3594.5666\n",
            "Epoch 225/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3220.3547 - mae: 3220.3547\n",
            "Epoch 226/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3468.0405 - mae: 3468.0405\n",
            "Epoch 227/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3300.7879 - mae: 3300.7879\n",
            "Epoch 228/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3335.7799 - mae: 3335.7799\n",
            "Epoch 229/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3654.9440 - mae: 3654.9440\n",
            "Epoch 230/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3744.4225 - mae: 3744.4225\n",
            "Epoch 231/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3245.3392 - mae: 3245.3392\n",
            "Epoch 232/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.1329 - mae: 3498.1329\n",
            "Epoch 233/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3404.5886 - mae: 3404.5886\n",
            "Epoch 234/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3051.3312 - mae: 3051.3312\n",
            "Epoch 235/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3533.9160 - mae: 3533.9160\n",
            "Epoch 236/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3297.6052 - mae: 3297.6052\n",
            "Epoch 237/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3717.6991 - mae: 3717.6991\n",
            "Epoch 238/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3423.7645 - mae: 3423.7645\n",
            "Epoch 239/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3418.1871 - mae: 3418.1871\n",
            "Epoch 240/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3527.7074 - mae: 3527.7074\n",
            "Epoch 241/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.9980 - mae: 3675.9980\n",
            "Epoch 242/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3282.4969 - mae: 3282.4969\n",
            "Epoch 243/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3767.9450 - mae: 3767.9450\n",
            "Epoch 244/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3397.2011 - mae: 3397.2011\n",
            "Epoch 245/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3501.3923 - mae: 3501.3923\n",
            "Epoch 246/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3498.3268 - mae: 3498.3268\n",
            "Epoch 247/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3948 - mae: 3676.3948\n",
            "Epoch 248/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3747.8451 - mae: 3747.8451\n",
            "Epoch 249/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3505.7203 - mae: 3505.7203\n",
            "Epoch 250/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3440.2924 - mae: 3440.2924\n",
            "Epoch 251/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3535.3896 - mae: 3535.3896\n",
            "Epoch 252/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3414.2964 - mae: 3414.2964\n",
            "Epoch 253/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.2832 - mae: 3729.2832\n",
            "Epoch 254/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.8097 - mae: 3565.8097\n",
            "Epoch 255/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3144.2488 - mae: 3144.2488\n",
            "Epoch 256/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3274.8781 - mae: 3274.8781\n",
            "Epoch 257/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3567.9406 - mae: 3567.9406\n",
            "Epoch 258/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3488.7127 - mae: 3488.7127\n",
            "Epoch 259/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3439.7070 - mae: 3439.7070\n",
            "Epoch 260/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3293.3647 - mae: 3293.3647\n",
            "Epoch 261/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3599.6022 - mae: 3599.6022\n",
            "Epoch 262/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3474.8407 - mae: 3474.8407\n",
            "Epoch 263/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3550.5064 - mae: 3550.5064\n",
            "Epoch 264/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3548.0059 - mae: 3548.0059\n",
            "Epoch 265/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3375.0545 - mae: 3375.0545\n",
            "Epoch 266/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3321.4219 - mae: 3321.4219\n",
            "Epoch 267/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3565.7992 - mae: 3565.7992\n",
            "Epoch 268/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3594.7540 - mae: 3594.7540\n",
            "Epoch 269/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3097.0819 - mae: 3097.0819\n",
            "Epoch 270/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3322.1765 - mae: 3322.1765\n",
            "Epoch 271/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3359.2858 - mae: 3359.2858\n",
            "Epoch 272/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.7233 - mae: 3724.7233\n",
            "Epoch 273/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3420.7566 - mae: 3420.7566\n",
            "Epoch 274/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3543.3060 - mae: 3543.3060\n",
            "Epoch 275/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3367.0558 - mae: 3367.0558\n",
            "Epoch 276/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.3288 - mae: 3515.3288\n",
            "Epoch 277/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3412.1903 - mae: 3412.1903\n",
            "Epoch 278/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3393.4577 - mae: 3393.4577\n",
            "Epoch 279/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3623.2270 - mae: 3623.2270\n",
            "Epoch 280/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3339.5121 - mae: 3339.5121\n",
            "Epoch 281/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3551.9161 - mae: 3551.9161\n",
            "Epoch 282/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3254.2371 - mae: 3254.2371\n",
            "Epoch 283/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3278.5696 - mae: 3278.5696\n",
            "Epoch 284/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3489.3132 - mae: 3489.3132\n",
            "Epoch 285/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3564.3455 - mae: 3564.3455\n",
            "Epoch 286/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.0579 - mae: 3729.0579\n",
            "Epoch 287/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3995.4022 - mae: 3995.4022\n",
            "Epoch 288/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3460.8563 - mae: 3460.8563\n",
            "Epoch 289/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3515.9470 - mae: 3515.9470\n",
            "Epoch 290/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3344.8950 - mae: 3344.8950\n",
            "Epoch 291/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3635.9796 - mae: 3635.9796\n",
            "Epoch 292/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3516.7877 - mae: 3516.7877\n",
            "Epoch 293/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3430.5624 - mae: 3430.5624\n",
            "Epoch 294/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3601.1780 - mae: 3601.1780\n",
            "Epoch 295/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3553.1426 - mae: 3553.1426\n",
            "Epoch 296/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.1948 - mae: 3716.1948\n",
            "Epoch 297/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3206.9443 - mae: 3206.9443\n",
            "Epoch 298/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3585.8571 - mae: 3585.8571\n",
            "Epoch 299/300\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3217.9176 - mae: 3217.9176\n",
            "Epoch 300/300\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3580.3217 - mae: 3580.3217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe8524b1850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMmFM_G9vWcX",
        "outputId": "4aa4df1a-b883-4c45-a587-4d0e8db0204d"
      },
      "source": [
        "model_6.evaluate(X_test,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3159.1299 - mae: 3159.1299\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3159.1298828125, 3159.1298828125]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heTTDjEJeHTK"
      },
      "source": [
        "## Import the Boston pricing dataset from TensorFlow `tf.keras.datasets` and model it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDzJvi8yc8yk"
      },
      "source": [
        "# loading dataset\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(path='boston_housing.npz', test_split=0.2, seed=42)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45PsYxQNz43a",
        "outputId": "dd073c13-ce34-4c0c-bb01-273bfa549083"
      },
      "source": [
        "# model_7\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model_7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_7.compile(loss=\"mae\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "model_7.fit(X_train,y_train,epochs=100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 31.8639 - mae: 31.8639\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 9.1479 - mae: 9.1479\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.4544 - mae: 7.4544\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.8269 - mae: 6.8269\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.9014 - mae: 6.9014\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.7529 - mae: 6.7529\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.3700 - mae: 6.3700\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2976 - mae: 6.2976\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 8.0219 - mae: 8.0219\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.6015 - mae: 6.6015\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4094 - mae: 6.4094\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8840 - mae: 5.8840\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.0005 - mae: 6.0005\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.1742 - mae: 6.1742\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8163 - mae: 5.8163\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7192 - mae: 5.7192\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7322 - mae: 5.7322\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2668 - mae: 5.2668\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2219 - mae: 6.2219\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 7.0518 - mae: 7.0518\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.4195 - mae: 6.4195\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7709 - mae: 5.7709\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4775 - mae: 5.4775\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.6571 - mae: 5.6571\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3063 - mae: 5.3063\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1121 - mae: 5.1121\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9892 - mae: 5.9892\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.8665 - mae: 5.8665\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2160 - mae: 6.2160\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4535 - mae: 5.4535\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2596 - mae: 5.2596\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0072 - mae: 5.0072\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8035 - mae: 4.8035\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9015 - mae: 4.9015\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3490 - mae: 5.3490\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9483 - mae: 4.9483\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2244 - mae: 5.2244\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3318 - mae: 5.3318\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.0473 - mae: 6.0473\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8614 - mae: 5.8614\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6919 - mae: 5.6919\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7670 - mae: 5.7670\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0491 - mae: 5.0491\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1259 - mae: 5.1259\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3796 - mae: 4.3796\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.8615 - mae: 4.8615\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6521 - mae: 5.6521\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 7.3768 - mae: 7.3768\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.5634 - mae: 5.5634\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4958 - mae: 5.4958\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5148 - mae: 4.5148\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.3247 - mae: 5.3247\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9865 - mae: 4.9865\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4806 - mae: 4.4806\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4257 - mae: 4.4257\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0424 - mae: 5.0424\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.4746 - mae: 5.4746\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8895 - mae: 4.8895\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5161 - mae: 4.5161\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0152 - mae: 5.0152\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0343 - mae: 5.0343\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.7038 - mae: 4.7038\n",
            "Epoch 63/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4935 - mae: 4.4935\n",
            "Epoch 64/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3717 - mae: 4.3717\n",
            "Epoch 65/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7771 - mae: 4.7771\n",
            "Epoch 66/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.9289 - mae: 4.9289\n",
            "Epoch 67/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6808 - mae: 4.6808\n",
            "Epoch 68/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1566 - mae: 4.1566\n",
            "Epoch 69/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5836 - mae: 4.5836\n",
            "Epoch 70/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2521 - mae: 4.2521\n",
            "Epoch 71/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4528 - mae: 4.4528\n",
            "Epoch 72/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4967 - mae: 4.4967\n",
            "Epoch 73/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2231 - mae: 4.2231\n",
            "Epoch 74/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6210 - mae: 4.6210\n",
            "Epoch 75/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4655 - mae: 4.4655\n",
            "Epoch 76/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4745 - mae: 4.4745\n",
            "Epoch 77/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0346 - mae: 5.0346\n",
            "Epoch 78/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.8491 - mae: 5.8491\n",
            "Epoch 79/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6237 - mae: 4.6237\n",
            "Epoch 80/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.5865 - mae: 4.5865\n",
            "Epoch 81/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1605 - mae: 5.1605\n",
            "Epoch 82/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 6.2266 - mae: 6.2266\n",
            "Epoch 83/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.0907 - mae: 5.0907\n",
            "Epoch 84/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3679 - mae: 4.3679\n",
            "Epoch 85/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.7067 - mae: 5.7067\n",
            "Epoch 86/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4635 - mae: 4.4635\n",
            "Epoch 87/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.6952 - mae: 4.6952\n",
            "Epoch 88/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4430 - mae: 4.4430\n",
            "Epoch 89/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2909 - mae: 4.2909\n",
            "Epoch 90/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.4434 - mae: 4.4434\n",
            "Epoch 91/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.2810 - mae: 5.2810\n",
            "Epoch 92/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.1791 - mae: 5.1791\n",
            "Epoch 93/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.3246 - mae: 4.3246\n",
            "Epoch 94/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4481 - mae: 4.4481\n",
            "Epoch 95/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.2419 - mae: 4.2419\n",
            "Epoch 96/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8541 - mae: 4.8541\n",
            "Epoch 97/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 5.9016 - mae: 5.9016\n",
            "Epoch 98/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 4.0906 - mae: 4.0906\n",
            "Epoch 99/100\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0464 - mae: 4.0464\n",
            "Epoch 100/100\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 3.9151 - mae: 3.9151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe852355110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-ukOmMNz8yZ",
        "outputId": "ef882c74-7358-4b59-bc08-c00bcf54586d"
      },
      "source": [
        "model_7.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 100)               1400      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 2,531\n",
            "Trainable params: 2,531\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAJWFJve01xx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}